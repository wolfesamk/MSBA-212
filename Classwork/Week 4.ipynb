{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sam\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\facebook_scraper\\facebook_scraper.py:912: UserWarning: Facebook says 'Unsupported Browser'\n",
      "  warnings.warn(f\"Facebook says 'Unsupported Browser'\")\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.001986265182495117,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 100,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73e7b6adae0f4fff866d5b578e57be7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Peter Hoey Currently the scarf can only be purchased with the ticket package.\n",
      "\n",
      "\n",
      "Next Comment\n",
      "Peter Hoey Apologies for dropping this here but it feels too great to visit your timeline, i always enjoy what you share here on facebook but we are not friends yet, i have tried several times to send the friend request but its not going through. do you mind trying from your side?i will be happy to be friends with you.if you find this message embarrassing please pardon my manners.thank you and remain blessed\n",
      "\n",
      "\n",
      "Next Comment\n",
      "Idalia Mendoza Guerrero I know but Im going to be out of town! üò©\n",
      "\n",
      "\n",
      "Next Comment\n",
      "If you go, get me a scarf? ü§ûüèº\n",
      "\n",
      "\n",
      "Next Comment\n",
      "Nicole Mendoza i clicked the link & it says no tickets. üò≠\n",
      "\n",
      "\n",
      "Next Comment\n",
      "Nicole Mendoza but if I manage to snag one I will!\n",
      "\n",
      "\n",
      "Next Comment\n",
      "Alex-a Rosalia Scarves were temporarily sold out, which affected this specific ticket package. Working on getting more scarves and having the link back up. Timing tbd. Thank you.\n",
      "\n",
      "\n",
      "Next Comment\n",
      "Kevin Winter Currently the scarf can only be purchased with the ticket package.\n",
      "\n",
      "\n",
      "Next Comment\n",
      "Erica N Brown Apologies for dropping this here but it feels too great to visit your timeline, i always enjoy what you share here on facebook but we are not friends yet, i have tried several times to send the friend request but its not going through. do you mind trying from your side?i will be happy to be friends with you.if you find this message embarrassing please pardon my manners.thank you and remain blessed\n",
      "\n",
      "\n",
      "Next Comment\n",
      "Samuel S Saeteurn - Wanna go?\n",
      "\n",
      "\n",
      "Next Comment\n",
      "Linda Luong-Saeteurn no lol\n",
      "\n",
      "\n",
      "Next Comment\n",
      "Jacob Wayne Mickelson-Steel\n",
      "e Thanks for letting us know. We're looking into it.\n",
      "\n",
      "\n",
      "Next Comment\n",
      "Jacob Wayne Mickelson-Steel\n",
      "e The issue has been resolved. Thank you!\n",
      "\n",
      "\n",
      "Next Comment\n",
      "Jacob WayneApologies for dropping this here but it feels too great to visit your timeline, i always enjoy what you share here on facebook but we are not friends yet, i have tried several times to send the friend request but its not going through. do you mind trying from your side?i will be happy to be friends with you.if you find this message embarrassing please pardon my manners.thank you and remain blessed Mickelson-Steel\n",
      "e\n",
      "\n",
      "\n",
      "Next Comment\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "#example 1\n",
    "#https://github.com/kevinzg/facebook-scraper\n",
    "import facebook_scraper as fs\n",
    "import pandas\n",
    "\n",
    "# get POST_ID from the URL of the post which can have the following structure:\n",
    "# https://www.facebook.com/USER/posts/POST_ID\n",
    "# https://www.facebook.com/groups/GROUP_ID/posts/POST_ID\n",
    "#This is the Sac State post I am using\n",
    "#https://www.facebook.com/sacstate/posts/pfbid02tD4AnaqmDrfFVgzdW6qguf9GBrDB9v9uHof6TY1bXtj974dX26zRfwQCRzhEbJVzl\n",
    "POST_ID = \"pfbid02tD4AnaqmDrfFVgzdW6qguf9GBrDB9v9uHof6TY1bXtj974dX26zRfwQCRzhEbJVzl\"\n",
    "\n",
    "# number of comments to download -- set this to True to download all comments\n",
    "#FYI if you try to download thousands of comments, Facebook will likely block your IP address\n",
    "MAX_COMMENTS = 100\n",
    "\n",
    "# get the post (this gives a generator)\n",
    "gen = fs.get_posts(\n",
    "    post_urls=[POST_ID],\n",
    "    options={\"comments\": MAX_COMMENTS, \"progress\": True}\n",
    ")\n",
    "\n",
    "# take 1st element of the generator which is the post we requested\n",
    "post = next(gen)\n",
    "\n",
    "# extract the comments part\n",
    "comments = post['comments_full']\n",
    "\n",
    "# process comments as you want...\n",
    "output = {\"CommentID\":[],\"CommentURL\":[],\"CommenterID\":[], \"Comment\":[], \"CommentReactions\":[],\"CommentReactionCount\":[]}\n",
    "output2={\"Comment\":[],\"CommentReactions\":[],\"CommentReactionCount\":[],\"Replies\":[]}\n",
    "for comment in comments:\n",
    "\n",
    "    # e.g. ...print them\n",
    "    #print(comment)\n",
    "    output['CommentID'].append(comment['comment_id'])\n",
    "    output['CommentURL'].append(comment['comment_url'])\n",
    "    output['CommenterID'].append(comment['comment_id'])\n",
    "    output['Comment'].append(comment['comment_text'])\n",
    "    output['CommentReactions'].append(comment['comment_reactions'])\n",
    "    output['CommentReactionCount'].append(comment['comment_reaction_count'])\n",
    "\n",
    "    # e.g. ...get the replies for them\n",
    "    for reply in comment['replies']:\n",
    "        reply=reply['comment_text']\n",
    "        if not reply:\n",
    "            reply=\"Empty\"\n",
    "        print(reply)\n",
    "        print(\"\\n\")\n",
    "        print(\"Next Comment\")\n",
    "        output2['Comment'].append(comment['comment_text'])\n",
    "        output2['CommentReactions'].append(comment['comment_reactions'])\n",
    "        output2['CommentReactionCount'].append(comment['comment_reaction_count'])\n",
    "        output2['Replies'].append(reply)\n",
    "\n",
    "\n",
    "\n",
    "results = pandas.DataFrame(output)\n",
    "results.to_csv('example1results.csv', index=True, index_label=\"Index\")\n",
    "results2 = pandas.DataFrame(output2)\n",
    "results2.to_csv('replies.csv', index=True, index_label=\"Index\")\n",
    "print(\"done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pizza Twist - Downtown\n",
      "This location just opened and I couldn't be happier! I called my order in and Love told me all the specials. I ordered a small butter chicken pizza. Flavors were great and tasted‚Ä¶\n",
      "5.0 \n",
      "(2 reviews)\n",
      "2 reviews\n",
      "Salad\n",
      "Delivery, Takeout\n",
      "None\n",
      "Queen-Status Urban Difference Restaurant\n",
      "We are brand new and now open for business and taking orders We are a soul food restaurant who does things a little bit different. We want you to come eat, enjoy and embrace your‚Ä¶\n",
      "\n",
      "\n",
      "\n",
      "Soul Food\n",
      "Delivery\n",
      "None\n",
      "Pocha House\n",
      "Our bartender, Felicia was very attentive and kind! She served us quickly and welcomed us as soon as we came in :)\n",
      "4.2 \n",
      "(150 reviews)\n",
      "150 reviews\n",
      "Korean\n",
      "Outdoor seating, Takeout\n",
      "$$\n",
      "Hidden Dumpling House Midtown\n",
      "This place is REALLY good. Well worth the wait, I don't think people should complain about having to wait a long time to get a table if it's always packed. The‚Ä¶\n",
      "3.8 \n",
      "(188 reviews)\n",
      "188 reviews\n",
      "Chinese\n",
      "Waitlist opens at 11:00 am, Outdoor seating, Delivery, Takeout\n",
      "$$\n",
      "Seoul St Midtown\n",
      "Great people great food the bartenders are just good people nice to talk to and take care of you\n",
      "4.3 \n",
      "(348 reviews)\n",
      "348 reviews\n",
      "Korean\n",
      "Outdoor seating, Delivery, Takeout\n",
      "$$\n",
      "The Rind\n",
      "I went there for a last minute gathering one of the Managers was able to put together a nice charcuterie board for to-go for me! She was very Nice willingly to‚Ä¶\n",
      "4.4 \n",
      "(1.2k reviews)\n",
      "1.2k reviews\n",
      "American (New)\n",
      "Outdoor seating, Takeout\n",
      "$$\n",
      "Buddha Belly Burger\n",
      "Vegan, without all the pomp and circumstance!\n",
      "\n",
      "I won't lie, any time I find myself patronizing a 'vegan' restaurant, I go in a little hesitant.\n",
      "\n",
      "I WAS WRONG‚Ä¶\n",
      "4.7 \n",
      "(111 reviews)\n",
      "111 reviews\n",
      "Burgers\n",
      "Outdoor seating, Delivery, Takeout\n",
      "$$\n",
      "Historic Star Lounge\n",
      "Great ambiance, food, drinks, and service! A great find in the Sacramento area. Menu and drinks change frequently, and I'm always excited to get in and try‚Ä¶\n",
      "4.4 \n",
      "(100 reviews)\n",
      "100 reviews\n",
      "Lounges\n",
      "Outdoor seating, Delivery\n",
      "None\n",
      "Adamo‚Äôs\n",
      "Came to town to visit a friend and decided we wanted pasta!\n",
      "\n",
      "Oh mannnnnn! This was divine!\n",
      "\n",
      "So first of all they make EVERYTHING in house (besides the tomatoes‚Ä¶\n",
      "4.2 \n",
      "(646 reviews)\n",
      "646 reviews\n",
      "American (New)\n",
      "Outdoor seating, Delivery, Takeout\n",
      "$$\n",
      "Fieldwork Brewing Company\n",
      "Friendly service and very good food. Pita with hummus and papitas is excellent. Wonderdul ioad and sours, always leave with a few for home. Please update the‚Ä¶\n",
      "4.4 \n",
      "(318 reviews)\n",
      "318 reviews\n",
      "Breweries\n",
      "Outdoor seating, Delivery, Takeout\n",
      "$$\n",
      "Frog & Slim\n",
      "Had a great dinner. The service was good. A place I would recommend UNTIL I checked the bill!  \n",
      "The martini was 14.00 with an additional $2.00 charge for the‚Ä¶\n",
      "4.6 \n",
      "(344 reviews)\n",
      "344 reviews\n",
      "American (New)\n",
      "Outdoor seating, Delivery, Takeout\n",
      "$$\n",
      "¬†Roscoe‚Äôs Bar & Burgers\n",
      "Staff is very friendly and the design of the restaurant is amazing! \n",
      "\n",
      "Their fries here are so addicting, it makes you just wanna make that your own meal! The‚Ä¶\n",
      "4.4 \n",
      "(70 reviews)\n",
      "70 reviews\n",
      "Burgers\n",
      "Outdoor seating, Delivery, Takeout\n",
      "$$\n",
      "Teriyaki Madness\n",
      "Teriyaki Madness serves up crazy delicious, fresh Japanese-inspired Teriyaki bowls, full of flavor: Chicken, Steak, Tofu, Veggies, Noodles, Rice, Fried Rice. Customize your bowl. We‚Ä¶\n",
      "\n",
      "\n",
      "\n",
      "Noodles\n",
      "Outdoor seating, Delivery, Takeout\n",
      "None\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "#example 2\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas\n",
    "\n",
    "# Get data by pretending we are a browser like this.\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_2) AppleWebKit/601.3.9 (KHTML, like Gecko) Version/9.0.2 Safari/601.3.9'}\n",
    "url = 'https://www.yelp.com/search?cflt=restaurants&find_loc=Midtown%2C+Sacramento%2C+CA'\n",
    "response = requests.get(url, headers=headers)\n",
    "\n",
    "# print(response)\n",
    "# response 200 means that it is working\n",
    "\n",
    "soup = BeautifulSoup(response.content, 'lxml')\n",
    "\n",
    "#I am creating an empty dictionary here\n",
    "output = {\"Name\":[],\"Description\":[],\"Cuisine\":[], \"Features\":[], \"Price\":[],\"AverageReviewScore\":[],\"NumberOfReviews\":[]}\n",
    "\n",
    "for item in soup.select('[class*=container]'):\n",
    "    try:\n",
    "        # print(item)\n",
    "        if item.find('h3'):\n",
    "            name = item.find('h3').get_text()\n",
    "            if name[0].isdigit():\n",
    "             name=name[3:]\n",
    "            print(name)\n",
    "            description = item.find('p', attrs={'class':'css-16lklrv'})\n",
    "            descriptioninstring=str(description)\n",
    "            fixeddescription=descriptioninstring[24:]\n",
    "            seperator = '‚Äù'\n",
    "            strippeddescription = fixeddescription.split(seperator, 1)[0]\n",
    "            print(strippeddescription)\n",
    "            averagereviewscore = item.find('span', class_='css-gutk1c')\n",
    "            averagereviewscoreinstring = str(averagereviewscore)\n",
    "            fixedaverageratingscore = averagereviewscoreinstring[53:]\n",
    "            seperator = '<'\n",
    "            strippedaverageratingscore = fixedaverageratingscore.split(seperator, 1)[0]\n",
    "            print(strippedaverageratingscore)\n",
    "\n",
    "            #Confusion with the location both have the same span class name\n",
    "            numberofreviews = item.find('span', class_='css-chan6m').get_text()\n",
    "            print(numberofreviews)\n",
    "            fixednumberofreviews = numberofreviews[1:]\n",
    "            fixednumberofreviews=fixednumberofreviews.replace(')', '')\n",
    "            print(fixednumberofreviews)\n",
    "\n",
    "            #Alternative attempt does not always work good\n",
    "            #numberofreviewstext = item.find('div', attrs={'class':'css-1qn0b6x'}).get_text()\n",
    "            #if 'reviews' in numberofreviewstext:\n",
    "             #separator = 'reviews'\n",
    "             #fixingnumberofreviews = numberofreviewstext.split(separator, 1)[0]\n",
    "             #fixingnumberofreviews = fixingnumberofreviews[fixingnumberofreviews.find(' ('):]\n",
    "             #fixednumberofreviews = fixingnumberofreviews[2:]\n",
    "             #print(fixednumberofreviews)\n",
    "            #else:\n",
    "                #fixednumberofreviews = ''\n",
    "\n",
    "\n",
    "            cuisine = item.find('span', class_='css-11bijt4').get_text()\n",
    "            print(cuisine)\n",
    "            features = item.find_all('span', class_='raw__09f24__T4Ezm')\n",
    "            featuresinstring = str(features)\n",
    "            fixedfeatures=featuresinstring.replace('<span class=\"raw__09f24__T4Ezm\">', '')\n",
    "            fixedfeatures = fixedfeatures.replace('[', '')\n",
    "            fixedfeatures = fixedfeatures.replace(']', '')\n",
    "            fixedfeatures = fixedfeatures.replace('</span>', '')\n",
    "            print(fixedfeatures)\n",
    "            price = item.find('span', class_='priceRange__09f24__mmOuH css-blvn7s')\n",
    "            priceinstring = str(price)\n",
    "            fixedprice = priceinstring.replace('<span class=\"priceRange__09f24__mmOuH css-blvn7s\">', '')\n",
    "            fixedprice = fixedprice.replace('</span>', '')\n",
    "            print(fixedprice)\n",
    "            #Append all cleaned data to the empty dictionary\n",
    "            output['Name'].append(name)\n",
    "            output['Description'].append(strippeddescription)\n",
    "            output['Cuisine'].append(cuisine)\n",
    "            output['Features'].append(fixedfeatures)\n",
    "            output['Price'].append(fixedprice)\n",
    "            output['AverageReviewScore'].append(strippedaverageratingscore)\n",
    "            output['NumberOfReviews'].append(fixednumberofreviews)\n",
    "\n",
    "    except Exception as e:\n",
    "        raise e\n",
    "        print('')\n",
    "\n",
    "results = pandas.DataFrame(output)\n",
    "results.to_csv('example2results.csv', index=True, index_label=\"Index\")\n",
    "print(\"done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Ravine on Sixteen\n",
      "We, The Ravine On Sixteen are happy to welcome all visitors. We have dedicated ourselves to making sure your experience is enjoyable and memorable. We are Yolo County's new \"Place to‚Ä¶\n",
      "4.2 \n",
      "46 reviews\n",
      "Burgers\n",
      "Outdoor seating, Delivery, Takeout\n",
      "None\n",
      "Aladdin‚Äôs Grill\n",
      "Grand Opening May 26th! Aladdin's Grill is a delectable destination that offers an enticing array of gyros, shawarmas, and cheesesteaks, taking your taste buds on a tantalizing‚Ä¶\n",
      "4.5 \n",
      "87 reviews\n",
      "Fast Food\n",
      "Delivery, Takeout\n",
      "None\n",
      "Mojo‚Äôs Lounge & Kitchen428 Restaurant\n",
      "In town for a few days and stumbled upon this spot right before last call.  We ordered vegan coconut curry and wow!  I want another bowl to take home.  It is‚Ä¶\n",
      "4.3 \n",
      "489 reviews\n",
      "American (New)\n",
      "Live wait time: 0 mins, Outdoor seating, Delivery, Takeout\n",
      "None\n",
      "Morgan‚Äôs On Main\n",
      "The mock-tails are delightful and so fun to go with my kid. The atmosphere is pretty lively and I appreciate the service.\n",
      "4.0 \n",
      "329 reviews\n",
      "American (New)\n",
      "Outdoor seating, Takeout\n",
      "None\n",
      "He‚Äôs From Philly Cheesesteaks\n",
      "Went when it wasn't too busy. Ordered two traditional philly, a pizza philly, and philly fries. Probably what makes this place stand out is that they're‚Ä¶\n",
      "4.5 \n",
      "13 reviews\n",
      "Sandwiches\n",
      "Opened 3 weeks ago\n",
      "None\n",
      "Main Street Lounge\n",
      "I love this place! The food is always on point. Great service. For being a new place and new owners they are doing a great job. Would recommend for brunch with‚Ä¶\n",
      "4.5 \n",
      "46 reviews\n",
      "Pizza\n",
      "Outdoor seating, Delivery, Takeout\n",
      "None\n",
      "Blue Note Brewing Company\n",
      "Blue Note is a great local brewery which offers a wide range of beer styles which I can always find a favorite.\n",
      "\n",
      "They have plenty of seating inside and outside‚Ä¶\n",
      "4.3 \n",
      "123 reviews\n",
      "Breweries\n",
      "Outdoor seating, Delivery, Takeout\n",
      "None\n",
      "Pete‚Äôs Restaurant & Brewhouse\n",
      "Visited this location on a weekday and it wasn't busy at all. The wait for service was very slow though although there were plenty of employees. \n",
      "\n",
      "Once we got‚Ä¶\n",
      "3.8 \n",
      "362 reviews\n",
      "Pizza\n",
      "Outdoor seating, Delivery, Takeout\n",
      "None\n",
      "Pupuseria La Chicana\n",
      "Incredible and wonderful and very good and delicious. To start the seating area is a little tent directly outside the interior, giving a homey, casual vibe.‚Ä¶\n",
      "4.3 \n",
      "492 reviews\n",
      "Mexican\n",
      "Outdoor seating, Takeout\n",
      "None\n",
      "The HIVE Tasting Room and Kitchen\n",
      "If you want to do an amazing honey tasting, drive to this place!! \n",
      "Great gift ideas!!!\n",
      "Lunch and special events also offered! So much honey- oh, and mead but‚Ä¶\n",
      "4.6 \n",
      "34 reviews\n",
      "American (New)\n",
      "Outdoor seating, Delivery, Takeout\n",
      "None\n",
      "Father Paddy‚Äôs\n",
      "This bar is great. The people who come here? Pretty awesome. Servers? Totally great. Food : We got GREAT bar food. \n",
      "\n",
      "This place reminds me of Philadelphia.‚Ä¶\n",
      "4.1 \n",
      "286 reviews\n",
      "Irish Pub\n",
      "Outdoor seating, Takeout\n",
      "None\n",
      "¬†Sakura\n",
      "We just had amazing service and phenomenal sushi! Their sushi sashimi for 2 was a great deal! Beautiful presentation, plus you get to choose two sushi rolls of‚Ä¶\n",
      "3.9 \n",
      "199 reviews\n",
      "Sushi Bars\n",
      "Outdoor seating, Delivery, Takeout\n",
      "None\n",
      "Oyster Bar\n",
      "Welcome to Oyster Bar where you can find great Seafood available for delivery or takeout. With many years of journey in the hospitality industry, Oyster Bar has made a mark for‚Ä¶\n",
      "4.1 \n",
      "237 reviews\n",
      "Seafood\n",
      "Make an Online Reservation, Outdoor seating, Delivery, Takeout\n",
      "None\n",
      "Jack in the Box\n",
      "So this review is about a very unique situation and the excellent customer service we got at this location: My cousin had a wedding up in Winters, CA, and as her fiance is Belgian,‚Ä¶\n",
      "\n",
      "\n",
      "Burgers\n",
      "Delivery, Takeout\n",
      "None\n",
      "The Ravine on Sixteen\n",
      "We, The Ravine On Sixteen are happy to welcome all visitors. We have dedicated ourselves to making sure your experience is enjoyable and memorable. We are Yolo County's new \"Place to‚Ä¶\n",
      "4.2 \n",
      "46 reviews\n",
      "Pizza\n",
      "Outdoor seating, Delivery, Takeout\n",
      "None\n",
      "¬†MAX TASTE - Lahorian Grill\n",
      "\n",
      "4.3 \n",
      "73 reviews\n",
      "Indian\n",
      "Outdoor seating, Delivery, Takeout\n",
      "None\n",
      "¬†Kuji Asian Grill\n",
      "The food is delicious, the sushi comes around on the belt and a robot brings your drinks. It's a cool experience and perfect for sushi lovers\n",
      "4.7 \n",
      "382 reviews\n",
      "Korean\n",
      "Outdoor seating, Delivery, Takeout\n",
      "None\n",
      "¬†The Burger Saloon\n",
      "I've gotta say - these guys do burgers right. The menu is a little daunting (lots of options). But, I haven't had a bad burger yet.\n",
      "\n",
      "I also enjoy asking the‚Ä¶\n",
      "4.1 \n",
      "621 reviews\n",
      "Bars\n",
      "Outdoor seating, Delivery, Takeout\n",
      "None\n",
      "¬†Osaka Sushi Japanese Restaurant\n",
      "I'm amazed they were even open afrer losing electricity because of the big fire that day. It was a birthday dinner for my sister and very much enjoyed it. Upon‚Ä¶\n",
      "4.0 \n",
      "370 reviews\n",
      "Japanese\n",
      "Waitlist is closed, Outdoor seating, Delivery, Takeout\n",
      "None\n",
      "¬†Doggeros\n",
      "We are always on the look out for a new spot to try out for lunch, also we don't head over to woodland very often so we decided to give it a shot.   One of the‚Ä¶\n",
      "4.1 \n",
      "241 reviews\n",
      "Burgers\n",
      "Outdoor seating, Delivery, Takeout\n",
      "None\n",
      "¬†After Hours Boba & Tea\n",
      "Love stopping here for a late night burg with my husband. First time we came, we split an order of mozzarella sticks and a bacon cheese burger. Everything was‚Ä¶\n",
      "3.9 \n",
      "36 reviews\n",
      "Bubble Tea\n",
      "Delivery, Takeout\n",
      "None\n",
      "¬†House of Shah Afghan Urban Eats\n",
      "Interesting Afghan American fusion spot in Woodland, CA of all places!\n",
      "\n",
      "I typically get the loaded salad with a chicken kabab. Full of fresh mixed lettuce‚Ä¶\n",
      "4.5 \n",
      "322 reviews\n",
      "Afghan\n",
      "Outdoor seating, Delivery, Takeout\n",
      "None\n",
      "¬†Corabella‚Äôs Restaurant\n",
      "Probably the best country fried chicken I've had to date, period.\n",
      "\n",
      "The country potatoes were good but a bit salty.\n",
      "\n",
      "Service was fast and the young man who‚Ä¶\n",
      "4.6 \n",
      "119 reviews\n",
      "Breakfast & Brunch\n",
      "Outdoor seating, Delivery, Takeout\n",
      "None\n",
      "¬†Yaquis Cantina\n",
      "Amazing street tacos ! Delicious margaritas and super fresh chips and salsa . Great customer service. The owner was very hospitable.\n",
      "3.3 \n",
      "4 reviews\n",
      "Mexican\n",
      "\n",
      "None\n",
      "¬†Thai Pepper\n",
      "Food Was Fantastic \n",
      "The Staff Super Friendly! \n",
      "The Atmosphere Is Super Cool And S√∫per Mel√≥ \n",
      "And Their S√∫per Clean Too ! \n",
      "Great service . Will Definitely Come‚Ä¶\n",
      "4.2 \n",
      "153 reviews\n",
      "Thai\n",
      "Outdoor seating, Delivery, Takeout\n",
      "None\n",
      "Oyster Bar\n",
      "Welcome to Oyster Bar where you can find great Seafood available for delivery or takeout. With many years of journey in the hospitality industry, Oyster Bar has made a mark for‚Ä¶\n",
      "4.1 \n",
      "237 reviews\n",
      "American (New)\n",
      "Make an Online Reservation, Outdoor seating, Delivery, Takeout\n",
      "None\n",
      "Jack in the Box\n",
      "\n",
      "\n",
      "\n",
      "Ice Cream & Frozen Yogurt\n",
      "Delivery, Takeout\n",
      "None\n",
      "The Ravine on Sixteen\n",
      "We, The Ravine On Sixteen are happy to welcome all visitors. We have dedicated ourselves to making sure your experience is enjoyable and memorable. We are Yolo County's new \"Place to‚Ä¶\n",
      "4.2 \n",
      "\n",
      "Burgers\n",
      "Outdoor seating, Delivery, Takeout\n",
      "None\n",
      "¬†Falafel Corner\n",
      "I have eaten here twice since they opened. It's more of a grab and go typed spot rather than a sit down restaurant with a server. I got a gyro bowl and falafel‚Ä¶\n",
      "4.8 \n",
      "\n",
      "Fast Food\n",
      "\n",
      "None\n",
      "¬†Las Brasas Tacos & Salsas\n",
      "I had the tacos and they were amazing. It was my first time and the she talked us through the menu and recommended options based on what we liked. The chips,‚Ä¶\n",
      "4.0 \n",
      "\n",
      "Tacos\n",
      "Outdoor seating, Delivery, Takeout\n",
      "None\n",
      "¬†O Teriyaki\n",
      "Service 10/10\n",
      "Portions 10/10\n",
      "Food 10/10\n",
      "\n",
      "I am so happy that I found this little hole in the wall. It's a perfect little gem.\n",
      "3.8 \n",
      "$\n",
      "Hawaiian\n",
      "Takeout\n",
      "None\n",
      "¬†Morgan‚Äôs Mill\n",
      "This place is cool and their food is very good. I will be coming back to try more items and enjoy the vibes. The people working here were very nice and got me‚Ä¶\n",
      "4.2 \n",
      "\n",
      "Coffee & Tea\n",
      "Outdoor seating, Takeout\n",
      "None\n",
      "¬†The Meltdown\n",
      "I ordered via DoorDash; food was pretty good! The sandwich had a lot of meat which I very much appreciated. The cheesecake toast dessert was a tiny bit dry and‚Ä¶\n",
      "4.0 \n",
      "\n",
      "Food Delivery Services\n",
      "Delivery\n",
      "None\n",
      "¬†El Pantano Marisqueria\n",
      "las pi√±as coladas muy buenas  recomendadas\n",
      "tengan algo de paciencia que vale la pena toda la comida que ordene estaba muy buena\n",
      "4.2 \n",
      "\n",
      "Seafood\n",
      "Outdoor seating, Delivery, Takeout\n",
      "None\n",
      "¬†Birrieria Mooooy\n",
      "The BEST tacos I have EVER HAD IN CALI !  We drive 20 min from home just for their delicious tacos!!! Always friendly service!! \n",
      "\n",
      "If you love some good carne‚Ä¶\n",
      "4.8 \n",
      "\n",
      "Food Trucks\n",
      "\n",
      "None\n",
      "¬†Zitio Sports-Bar and Grill\n",
      "Stopped by Zitios for a late night meal and drinks. We ordered a burrito and tacos which were sooo good! Spice level was perfect and the flavors rich. Service‚Ä¶\n",
      "3.9 \n",
      "\n",
      "Sports Bars\n",
      "Outdoor seating, Takeout\n",
      "None\n",
      "¬†Ranch Kitchen\n",
      "Delicious, friendly and cute !!! Thank you YELP and we will definitely be back next time we're in town\n",
      "4.2 \n",
      "\n",
      "Breakfast & Brunch\n",
      "Outdoor seating, Delivery, Takeout\n",
      "None\n",
      "¬†Savory Cafe\n",
      "Been 3 times and every time I been haven't been amazed. First time I went was the best, chicken and waffles. Went and 2nd time and got French toast and bacon‚Ä¶\n",
      "3.4 \n",
      "$\n",
      "Breakfast & Brunch\n",
      "Outdoor seating, Takeout\n",
      "None\n",
      "Oyster Bar\n",
      "Welcome to Oyster Bar where you can find great Seafood available for delivery or takeout. With many years of journey in the hospitality industry, Oyster Bar has made a mark for‚Ä¶\n",
      "4.1 \n",
      "atomas\n",
      "Cajun/Creole\n",
      "Make an Online Reservation, Outdoor seating, Delivery, Takeout\n",
      "None\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "#example 3\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas\n",
    "\n",
    "# Get data by pretending we are a browser like this.\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_2) AppleWebKit/601.3.9 (KHTML, like Gecko) Version/9.0.2 Safari/601.3.9'}\n",
    "urllist = ['https://www.yelp.com/search?cflt=restaurants&find_loc=Woodland%2C+CA','https://www.yelp.com/search?cflt=restaurants&find_loc=Woodland%2C+CA&start=10','https://www.yelp.com/search?cflt=restaurants&find_loc=Woodland%2C+CA&start=20']\n",
    "\n",
    "#I am creating an empty dictionary here\n",
    "output = {\"Name\":[],\"Description\":[],\"Cuisine\":[], \"Features\":[], \"Price\":[],\"AverageReviewScore\":[],\"NumberOfReviews\":[]}\n",
    "\n",
    "for url in urllist:\n",
    " response = requests.get(url, headers=headers)\n",
    "\n",
    "# print(response)\n",
    "# response 200 means that it is working\n",
    "\n",
    " soup = BeautifulSoup(response.content, 'lxml')\n",
    "\n",
    " for item in soup.select('[class*=container]'):\n",
    "    try:\n",
    "        # print(item)\n",
    "        if item.find('h3'):\n",
    "            name = item.find('h3').get_text()\n",
    "            if name[0].isdigit():\n",
    "             name=name[3:]\n",
    "            print(name)\n",
    "            description = item.find('p', attrs={'class':'css-16lklrv'})\n",
    "            descriptioninstring=str(description)\n",
    "            fixeddescription=descriptioninstring[24:]\n",
    "            seperator = '‚Äù'\n",
    "            strippeddescription = fixeddescription.split(seperator, 1)[0]\n",
    "            print(strippeddescription)\n",
    "            averagereviewscore = item.find('span', class_='css-gutk1c')\n",
    "            averagereviewscoreinstring = str(averagereviewscore)\n",
    "            fixedaverageratingscore = averagereviewscoreinstring[53:]\n",
    "            seperator = '<'\n",
    "            strippedaverageratingscore = fixedaverageratingscore.split(seperator, 1)[0]\n",
    "            print(strippedaverageratingscore)\n",
    "            numberofreviews = item.find('span', class_='css-chan6m').get_text()\n",
    "            fixednumberofreviews = numberofreviews[1:]\n",
    "            fixednumberofreviews=fixednumberofreviews.replace(')', '')\n",
    "            print(fixednumberofreviews)\n",
    "            cuisine = item.find('span', class_='css-11bijt4').get_text()\n",
    "            print(cuisine)\n",
    "            features = item.find_all('span', class_='raw__09f24__T4Ezm')\n",
    "            featuresinstring = str(features)\n",
    "            fixedfeatures=featuresinstring.replace('<span class=\"raw__09f24__T4Ezm\">', '')\n",
    "            fixedfeatures = fixedfeatures.replace('[', '')\n",
    "            fixedfeatures = fixedfeatures.replace(']', '')\n",
    "            fixedfeatures = fixedfeatures.replace('</span>', '')\n",
    "            print(fixedfeatures)\n",
    "            price = item.find('span', class_='priceRange__09f24__mmOuH css-blvn7s')\n",
    "            priceinstring = str(price)\n",
    "            fixedprice = priceinstring.replace('<span class=\"priceRange__09f24__mmOuH css-blvn7s\">', '')\n",
    "            fixedprice = fixedprice.replace('</span>', '')\n",
    "            print(fixedprice)\n",
    "            #Append all cleaned data to the empty dictionary\n",
    "            output['Name'].append(name)\n",
    "            output['Description'].append(strippeddescription)\n",
    "            output['Cuisine'].append(cuisine)\n",
    "            output['Features'].append(fixedfeatures)\n",
    "            output['Price'].append(fixedprice)\n",
    "            output['AverageReviewScore'].append(strippedaverageratingscore)\n",
    "            output['NumberOfReviews'].append(fixednumberofreviews)\n",
    "\n",
    "    except Exception as e:\n",
    "        raise e\n",
    "        print('')\n",
    "\n",
    "results = pandas.DataFrame(output)\n",
    "results.to_csv('example3results.csv', index=True, index_label=\"Index\")\n",
    "print(\"done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "#example 4\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import pandas\n",
    "\n",
    "r = requests.get('https://www.yelp.com/biz/i-love-teriyaki-no-7-woodland')\n",
    "#r = requests.get('https://www.yelp.com/biz/pocha-house-sacramento')\n",
    "soup = BeautifulSoup(r.text, 'html.parser')\n",
    "#print(soup)\n",
    "regex = re.compile('.*comment__09f24__D0cxf css-qgunke.*')\n",
    "results = soup.find_all('p', {'class':regex})\n",
    "reviews = [result.text for result in results]\n",
    "#print(reviews)\n",
    "regex2 = re.compile('.*user-passport-info.*')\n",
    "results2 = soup.find_all('div', {'class':regex2})\n",
    "reviewers = [result.text for result in results2]\n",
    "reviewers.pop(0)\n",
    "#print(reviewers)\n",
    "\n",
    "#Scrape review ratings\n",
    "regex3 = re.compile('.*five-stars.*')\n",
    "results3= soup.find_all('div', {'class':regex3})\n",
    "ratings = [result['aria-label'] for result in results3]\n",
    "\n",
    "# Replace no ratings with 0\n",
    "ratings = [sub.replace('(no rating)', '0') for sub in ratings]\n",
    "cleanedratings=[]\n",
    "#Just keep the number portion of 5 star rating like scraped data\n",
    "for rating in ratings:\n",
    "    cleanedrating = rating.replace(' star rating', '')\n",
    "    cleanedratings.append(cleanedrating)\n",
    "#Finally in this rating list the first 5 ratings do not come from the reviews so I delete them\n",
    "cleanedratings = cleanedratings[5:]\n",
    "#The last few ratings in the scraped data is also wrong so delete them\n",
    "cleanedratings = cleanedratings[:10]\n",
    "\n",
    "#Check to make sure that all the lists have equal length\n",
    "#print(len(reviews))\n",
    "#print(len(cleanedratings))\n",
    "#print(len(reviewers))\n",
    "\n",
    "#I am creating an empty dictionary here\n",
    "output = {\"Reviewer\":[],\"Review\":[],\"Rating\":[]}\n",
    "\n",
    "for rating in cleanedratings:\n",
    "    output['Rating'].append(rating)\n",
    "\n",
    "for reviewer in reviewers:\n",
    "    output['Reviewer'].append(reviewer)\n",
    "\n",
    "for review in reviews:\n",
    "    output['Review'].append(review)\n",
    "\n",
    "results = pandas.DataFrame(output)\n",
    "#print(results)\n",
    "results.to_csv('example4results.csv', index=True, index_label=\"Index\")\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#example 5\n",
    "#https://github.com/frizchar/yelp-reviews-scraping/blob/main/Web_Scraping.ipynb\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import pandas\n",
    "\n",
    "urllist = ['https://www.yelp.com/biz/pocha-house-sacramento','https://www.yelp.com/biz/pocha-house-sacramento?start=10']\n",
    "\n",
    "#I am creating an empty dictionary here\n",
    "output = {'Reviewer':[],\"Review\":[], 'Rating':[]}\n",
    "\n",
    "for url in urllist:\n",
    "    r = requests.get(url)\n",
    "    soup = BeautifulSoup(r.text, 'html.parser')\n",
    "    #print(soup)\n",
    "    #Scrape Reviews\n",
    "    regex = re.compile('.*comment.*')\n",
    "    results = soup.find_all('p', {'class':regex})\n",
    "    reviews = [result.text for result in results]\n",
    "    for review in reviews:\n",
    "        output['Review'].append(review)\n",
    "    #Scrape Reviewer Names\n",
    "    regex2 = re.compile('.*user-passport-info.*')\n",
    "    results2 = soup.find_all('div', {'class': regex2})\n",
    "    reviewers = [result.text for result in results2]\n",
    "    reviewers.pop(0)\n",
    "    for reviewer in reviewers:\n",
    "        output['Reviewer'].append(reviewer)\n",
    "    #Scrape Review Ratings\n",
    "    # Scrape review ratings\n",
    "    regex3 = re.compile('.*five-stars.*')\n",
    "    results3 = soup.find_all('div', {'class': regex3})\n",
    "    ratings = [result['aria-label'] for result in results3]\n",
    "\n",
    "    # Replace no ratings with 0\n",
    "    ratings = [sub.replace('(no rating)', '0') for sub in ratings]\n",
    "    cleanedratings = []\n",
    "    # Just keep the number portion of 5 star rating like scraped data\n",
    "    for rating in ratings:\n",
    "        cleanedrating = rating.replace(' star rating', '')\n",
    "        cleanedratings.append(cleanedrating)\n",
    "    # Finally in this rating list the first 5 ratings do not come from the reviews so I delete them\n",
    "    cleanedratings = cleanedratings[5:]\n",
    "    # The last few ratings in the scraped data is also wrong so delete them\n",
    "    cleanedratings = cleanedratings[:10]\n",
    "    for rating in cleanedratings:\n",
    "        output['Rating'].append(rating)\n",
    "\n",
    "\n",
    "results = pandas.DataFrame(output)\n",
    "print(results)\n",
    "results.to_csv('example5results.csv', index=True, index_label=\"Index\")\n",
    "print(\"done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#example 6\n",
    "#https://github.com/frizchar/yelp-reviews-scraping/blob/main/Web_Scraping.ipynb\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import pandas\n",
    "\n",
    "#I am creating an empty dictionary here\n",
    "output = {'Name':[],'CommonQuestions':[]}\n",
    "commonquestionslist=[]\n",
    "nameslist=[]\n",
    "\n",
    "\n",
    "urllist = ['https://www.yelp.com/biz/pocha-house-sacramento','https://www.yelp.com/biz/hidden-dumpling-house-midtown-sacramento','https://www.yelp.com/biz/the-rind-sacramento']\n",
    "\n",
    "for url in urllist:\n",
    "    r = requests.get(url)\n",
    "    soup = BeautifulSoup(r.text, 'html.parser')\n",
    "    # Scrape most common 2 questions\n",
    "    regex = re.compile('.*ux5mu6.*')\n",
    "    firstquestions = soup.find_all('p', {'class': regex})[2].text\n",
    "    secondquestions = soup.find_all('p', {'class': regex})[5].text\n",
    "    commonquestions=firstquestions+secondquestions\n",
    "    commonquestionslist.append(commonquestions)\n",
    "\n",
    "    #Scrape Restaurant Name\n",
    "    regex2 = re.compile('.*1se8maq.*')\n",
    "    result3 = soup.find_all('h1', {'class': regex2})\n",
    "    names=str(result3)\n",
    "    names=names.replace('[<h1 class=\"css-1se8maq\">','')\n",
    "    names = names.replace('</h1>]', '')\n",
    "    nameslist.append(names)\n",
    "\n",
    "for name in nameslist:\n",
    " output['Name'].append(name)\n",
    "\n",
    "for question in commonquestionslist:\n",
    " output['CommonQuestions'].append(question)\n",
    "\n",
    "results = pandas.DataFrame(output)\n",
    "#print(results)\n",
    "results.to_csv('example6results.csv', index=True, index_label=\"Index\")\n",
    "print(\"done\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
