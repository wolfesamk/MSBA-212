{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import io\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.util import ngrams\n",
    "from collections import Counter\n",
    "from textblob import TextBlob\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import textstat\n",
    "from statistics import mean\n",
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readFile(url):\n",
    "    download = requests.get(url).content\n",
    "    # Reading the downloaded content and turning it into a pandas dataframe\n",
    "    df = pd.read_csv(io.StringIO(download.decode('utf-8')))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'values'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32me:\\Aliit\\School\\MSBA\\212\\Git\\MSBA-212\\Classwork\\Week 3.ipynb Cell 3\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Aliit/School/MSBA/212/Git/MSBA-212/Classwork/Week%203.ipynb#W2sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m descriptiondictionary \u001b[39m=\u001b[39m inputdata\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mdescription\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Aliit/School/MSBA/212/Git/MSBA-212/Classwork/Week%203.ipynb#W2sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39m#print(type(descriptiondictionary))\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Aliit/School/MSBA/212/Git/MSBA-212/Classwork/Week%203.ipynb#W2sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Aliit/School/MSBA/212/Git/MSBA-212/Classwork/Week%203.ipynb#W2sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39m# I am converting the dictionary to a list so I can analyze the data\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/e%3A/Aliit/School/MSBA/212/Git/MSBA-212/Classwork/Week%203.ipynb#W2sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m descriptionlist \u001b[39m=\u001b[39m  \u001b[39mlist\u001b[39m(descriptiondictionary\u001b[39m.\u001b[39;49mvalues())\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Aliit/School/MSBA/212/Git/MSBA-212/Classwork/Week%203.ipynb#W2sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39m#print(type(descriptionlist))\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Aliit/School/MSBA/212/Git/MSBA-212/Classwork/Week%203.ipynb#W2sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m \n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Aliit/School/MSBA/212/Git/MSBA-212/Classwork/Week%203.ipynb#W2sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39m#convert list to string\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Aliit/School/MSBA/212/Git/MSBA-212/Classwork/Week%203.ipynb#W2sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39m#I need the data in string format for analysis purposes\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Aliit/School/MSBA/212/Git/MSBA-212/Classwork/Week%203.ipynb#W2sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m descriptioninstring \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'values'"
     ]
    }
   ],
   "source": [
    "# Example 5\n",
    "#I am creating a dictionary here titled inputdata\n",
    "inputdata={}\n",
    "#I am assigning the content of the csv file to my dictionary\n",
    "#header is my row in the csv file that is why header is 0 below\n",
    "inputdata = readFile(\"https://raw.githubusercontent.com/wolfesamk/MSBA-212/main/Classwork/example2results.csv\").to_dict()\n",
    "\n",
    "#We can use type to check the data type of a variable\n",
    "#print(type(inputdata))\n",
    "\n",
    "#I am using the column headers from the csv file to find the data I am interested to analyze\n",
    "\n",
    "# I created a new dictionary here for the description column in my csv file\n",
    "descriptiondictionary = inputdata.get('description')\n",
    "#print(type(descriptiondictionary))\n",
    "\n",
    "# I am converting the dictionary to a list so I can analyze the data\n",
    "descriptionlist =  list(descriptiondictionary.values())\n",
    "#print(type(descriptionlist))\n",
    "\n",
    "#convert list to string\n",
    "#I need the data in string format for analysis purposes\n",
    "descriptioninstring = ''\n",
    "for eachletter in  descriptionlist:\n",
    "    descriptioninstring += ' '+ str(eachletter)\n",
    "\n",
    "print(descriptioninstring)\n",
    "#print(type(descriptioninstring))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'descriptioninstring' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32me:\\Aliit\\School\\MSBA\\212\\Git\\MSBA-212\\Classwork\\Week 3.ipynb Cell 4\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/Aliit/School/MSBA/212/Git/MSBA-212/Classwork/Week%203.ipynb#W3sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Example 6\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/Aliit/School/MSBA/212/Git/MSBA-212/Classwork/Week%203.ipynb#W3sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m#Access to the string from the previous file and make the string lower case\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/Aliit/School/MSBA/212/Git/MSBA-212/Classwork/Week%203.ipynb#W3sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m lowercasedescriptions\u001b[39m=\u001b[39mdescriptioninstring\u001b[39m.\u001b[39mlower()\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/Aliit/School/MSBA/212/Git/MSBA-212/Classwork/Week%203.ipynb#W3sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m#print(lowercasedescriptions)\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/Aliit/School/MSBA/212/Git/MSBA-212/Classwork/Week%203.ipynb#W3sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/Aliit/School/MSBA/212/Git/MSBA-212/Classwork/Week%203.ipynb#W3sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m#remove the url from text to prevent a future error\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/Aliit/School/MSBA/212/Git/MSBA-212/Classwork/Week%203.ipynb#W3sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m lowercasedescriptions\u001b[39m=\u001b[39m re\u001b[39m.\u001b[39msub(\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mw+:\u001b[39m\u001b[39m\\\u001b[39m\u001b[39m/\u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m[\u001b[39m\u001b[39m\\\u001b[39m\u001b[39md\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mw-]+(\u001b[39m\u001b[39m\\\u001b[39m\u001b[39m.[\u001b[39m\u001b[39m\\\u001b[39m\u001b[39md\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mw-]+)*(?:(?:\u001b[39m\u001b[39m\\\u001b[39m\u001b[39m/[^\u001b[39m\u001b[39m\\\u001b[39m\u001b[39ms/]*))*\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m, lowercasedescriptions)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'descriptioninstring' is not defined"
     ]
    }
   ],
   "source": [
    "# Example 6\n",
    "#Access to the string from the previous file and make the string lower case\n",
    "lowercasedescriptions=descriptioninstring.lower()\n",
    "#print(lowercasedescriptions)\n",
    "\n",
    "#remove the url from text to prevent a future error\n",
    "lowercasedescriptions= re.sub(r'\\w+:\\/{2}[\\d\\w-]+(\\.[\\d\\w-]+)*(?:(?:\\/[^\\s/]*))*', '', lowercasedescriptions)\n",
    "#print(lowercasedescriptions)\n",
    "\n",
    "#remove the stop or common words from the string\n",
    "nltk.download('stopwords')\n",
    "#print(stopwords.words('english'))\n",
    "\n",
    "description_tokens = word_tokenize(lowercasedescriptions)\n",
    "\n",
    "description_tokens_without_stopwords = [word for word in description_tokens if not word in stopwords.words()]\n",
    "\n",
    "#print(description_tokens_without_stopwords )\n",
    "\n",
    "unigrams = ngrams(description_tokens_without_stopwords, 1)\n",
    "bigrams = ngrams(description_tokens_without_stopwords,2)\n",
    "trigrams = ngrams(description_tokens_without_stopwords,3)\n",
    "\n",
    "#print (Counter(unigrams))\n",
    "#print (Counter(bigrams))\n",
    "#print (Counter(trigrams))\n",
    "\n",
    "mostcommonunigrams = Counter(unigrams)\n",
    "#This will print top 3 unigrams\n",
    "print(mostcommonunigrams.most_common(3))\n",
    "\n",
    "mostcommonbigrams = Counter(bigrams)\n",
    "print(mostcommonbigrams.most_common(3))\n",
    "\n",
    "mostcommontrigrams = Counter(trigrams)\n",
    "print(mostcommontrigrams.most_common(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'values'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32me:\\Aliit\\School\\MSBA\\212\\Git\\MSBA-212\\Classwork\\Week 3.ipynb Cell 5\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Aliit/School/MSBA/212/Git/MSBA-212/Classwork/Week%203.ipynb#W4sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m descriptiondictionary \u001b[39m=\u001b[39m inputdata\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mdescription\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Aliit/School/MSBA/212/Git/MSBA-212/Classwork/Week%203.ipynb#W4sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39m# I am converting the dictionary to a list so I can analyze the data\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/e%3A/Aliit/School/MSBA/212/Git/MSBA-212/Classwork/Week%203.ipynb#W4sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m titlelist \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(titledictionary\u001b[39m.\u001b[39;49mvalues())\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Aliit/School/MSBA/212/Git/MSBA-212/Classwork/Week%203.ipynb#W4sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m descriptionlist \u001b[39m=\u001b[39m  \u001b[39mlist\u001b[39m(descriptiondictionary\u001b[39m.\u001b[39mvalues())\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Aliit/School/MSBA/212/Git/MSBA-212/Classwork/Week%203.ipynb#W4sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39m#convert list to string\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Aliit/School/MSBA/212/Git/MSBA-212/Classwork/Week%203.ipynb#W4sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39m#I need the data in string format for analysis purposes\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'values'"
     ]
    }
   ],
   "source": [
    "# Example 7\n",
    "#I am creating a dictionary here titled inputdata\n",
    "inputdata={}\n",
    "#I am assigning the content of the csv file to my dictionary\n",
    "#header is my row in the csv file that is why header is 0 below\n",
    "inputdata = readFile(\"https://raw.githubusercontent.com/wolfesamk/MSBA-212/main/Classwork/example4results.csv\").to_dict()\n",
    "\n",
    "#We can use type to check the data type of a variable\n",
    "#print(type(inputdata))\n",
    "\n",
    "#I am using the column headers from the csv file to find the data I am interested to analyze\n",
    "\n",
    "# I created a new dictionary here for the description column in my csv file\n",
    "titledictionary = inputdata.get('title')\n",
    "descriptiondictionary = inputdata.get('description')\n",
    "\n",
    "\n",
    "# I am converting the dictionary to a list so I can analyze the data\n",
    "titlelist = list(titledictionary.values())\n",
    "descriptionlist =  list(descriptiondictionary.values())\n",
    "\n",
    "\n",
    "#convert list to string\n",
    "#I need the data in string format for analysis purposes\n",
    "titleinstring = ''\n",
    "for eachtitleletter in  titlelist:\n",
    "    titleinstring += ' '+ eachtitleletter\n",
    "\n",
    "descriptioninstring = ''\n",
    "for eachdescriptionletter in  descriptionlist:\n",
    "    descriptioninstring += ' '+ eachdescriptionletter\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.util import ngrams\n",
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "\n",
    "#Access to the string from the previous file and make the string lower case\n",
    "lowercasedescriptions=descriptioninstring.lower()\n",
    "lowercasetitles=titleinstring.lower()\n",
    "\n",
    "#remove the url from text to prevent a future error\n",
    "lowercasedescriptions= re.sub(r'\\w+:\\/{2}[\\d\\w-]+(\\.[\\d\\w-]+)*(?:(?:\\/[^\\s/]*))*', '', lowercasedescriptions)\n",
    "lowercasetitles= re.sub(r'\\w+:\\/{2}[\\d\\w-]+(\\.[\\d\\w-]+)*(?:(?:\\/[^\\s/]*))*', '', lowercasetitles)\n",
    "#print(lowercasedescriptions)\n",
    "\n",
    "#remove the stop or common words from the string\n",
    "nltk.download('stopwords')\n",
    "#print(stopwords.words('english'))\n",
    "\n",
    "description_tokens = word_tokenize(lowercasedescriptions)\n",
    "title_tokens = word_tokenize(lowercasetitles)\n",
    "\n",
    "description_tokens_without_stopwords = [word for word in description_tokens if not word in stopwords.words()]\n",
    "\n",
    "title_tokens_without_stopwords = [word for word in title_tokens if not word in stopwords.words()]\n",
    "\n",
    "#print(description_tokens_without_stopwords )\n",
    "\n",
    "descriptionunigrams = ngrams(description_tokens_without_stopwords, 1)\n",
    "descriptionbigrams = ngrams(description_tokens_without_stopwords,2)\n",
    "descriptiontrigrams = ngrams(description_tokens_without_stopwords,3)\n",
    "\n",
    "titleunigrams = ngrams(title_tokens_without_stopwords, 1)\n",
    "titlebigrams = ngrams(title_tokens_without_stopwords,2)\n",
    "titletrigrams = ngrams(title_tokens_without_stopwords,3)\n",
    "\n",
    "#print (Counter(unigrams))\n",
    "#print (Counter(bigrams))\n",
    "#print (Counter(trigrams))\n",
    "\n",
    "mostcommondescriptionunigrams = Counter(descriptionunigrams)\n",
    "mostcommontitleunigrams = Counter(titleunigrams)\n",
    "#This will print top 3 unigrams\n",
    "print(\"Most Common Description Unigrams:\", mostcommondescriptionunigrams.most_common(3))\n",
    "print(\"Most Common Title Unigrams:\",mostcommontitleunigrams.most_common(3))\n",
    "\n",
    "mostcommondescriptionbigrams = Counter(descriptionbigrams)\n",
    "mostcommontitlebigrams = Counter(titlebigrams)\n",
    "print(\"Most Common Description Bigrams:\",mostcommondescriptionbigrams.most_common(3))\n",
    "print(\"Most Common Title Biigrams:\",mostcommontitlebigrams.most_common(3))\n",
    "\n",
    "mostcommondescriptiontrigrams = Counter(descriptiontrigrams)\n",
    "mostcommontitletrigrams = Counter(titletrigrams)\n",
    "print(\"Most Common Description Trigrams:\",mostcommondescriptiontrigrams.most_common(3))\n",
    "print(\"Most Common Title Trigrams:\",mostcommontitletrigrams.most_common(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "# Example 8\n",
    "#I am creating a dictionary here titled inputdata\n",
    "inputdata={}\n",
    "#I am assigning the content of the csv file to my dictionary\n",
    "#header is my row in the csv file that is why header is 0 below\n",
    "inputdata = pd.read_csv('example5results.csv', header=[0]).to_dict()\n",
    "\n",
    "#We can use type to check the data type of a variable\n",
    "#print(type(inputdata))\n",
    "\n",
    "#I am using the column headers from the csv file to find the data I am interested to analyze\n",
    "\n",
    "# I created a new dictionary here for the description column in my csv file\n",
    "descriptiondictionary = inputdata.get('Review')\n",
    "#I am converting the decription from dictionary to a list for the sentiment analyses below\n",
    "descriptionlist =  list(descriptiondictionary.values())\n",
    "\n",
    "textblob_results_list=[]\n",
    "vader_results_list=[]\n",
    "\n",
    "for i in range(len(descriptionlist )):\n",
    "    #This is TextBlob Based Sentiment Analysis\n",
    "    textblob_analyze_polarity = TextBlob(descriptionlist [i]).polarity\n",
    "    textblob_analyze_subjectivity = TextBlob(descriptionlist [i]).subjectivity\n",
    "    #polarity values range from -1 to 1 where -1.0 is negative polarity and 1.0 is positive\n",
    "    #Subjectivity/objectivity  values range from 0.0 to 1.0 where 0.0 is very objective and 1.0 is very subjective\n",
    "    #print(\"Polarity: \", textblob_analyze_polarity)\n",
    "    #print(\"Subjectivity: \",textblob_analyze_subjectivity)\n",
    "\n",
    "    textblob_result = {\"TextBlob Polarity Score\":textblob_analyze_polarity,\"TextBlob Subjectivity Score\": textblob_analyze_subjectivity}\n",
    "    textblob_results_list.append(textblob_result)\n",
    "\n",
    "    #This is Vader Based Sentiment Analysis\n",
    "    #Vader provides 4 results labeled as negative, neutral, positive, and compound(overall)\n",
    "    vader_sentiment_analysis = SentimentIntensityAnalyzer().polarity_scores(descriptionlist [i])\n",
    "    vader_results_list.append(vader_sentiment_analysis)\n",
    "    #In Vader the compound score is the sum of positive, negative, and neutral scores which is then\n",
    "    #normalized between -1 [most extreme negative] and 1[most extreme positive]\n",
    "    #negative represents negative aspects of a tweet\n",
    "    #positive represents positive aspects of a tweet\n",
    "    #neutral represents neutral aspects of a tweet\n",
    "    #print(\"Polarity Scores in Vader: \", vader_sentiment_analysis)\n",
    "\n",
    "#This is the TextBlob Sentiment Analysis Results\n",
    "textblobresults = pd.DataFrame(textblob_results_list)\n",
    "\n",
    "#This is the Vader Sentiment Analysis Results\n",
    "vaderresults = pd.DataFrame(vader_results_list)\n",
    "#print(textblobresults['TextBlob Polarity Score'])\n",
    "#print(vaderresults['neg'])\n",
    "\n",
    "file = pd.read_csv('example5results.csv', header=[0])\n",
    "file['TextBlob Polarity Score'] = textblobresults['TextBlob Polarity Score']\n",
    "file['TextBlob Subjectivity Score'] = textblobresults['TextBlob Subjectivity Score']\n",
    "file['Vader Negative Polarity Score'] = vaderresults['neg']\n",
    "file['Vader Neutral Polarity Score'] = vaderresults['neu']\n",
    "file['Vader Positive Polarity Score'] = vaderresults['pos']\n",
    "file['Vader Compound Polarity Score'] = vaderresults['compound']\n",
    "\n",
    "#Index is false because example 1.csv file already has an index column\n",
    "file.to_csv('example8results.csv', index=True, index_label=\"Index\")\n",
    "\n",
    "print(\"done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "# Example 9\n",
    "#I am creating a dictionary here titled inputdata\n",
    "inputdata={}\n",
    "#I am assigning the content of the csv file to my dictionary\n",
    "#header is my row in the csv file that is why header is 0 below\n",
    "inputdata = pd.read_csv('example8results.csv', header=[0]).to_dict()\n",
    "\n",
    "#We can use type to check the data type of a variable\n",
    "#print(type(inputdata))\n",
    "\n",
    "#I am using the column headers from the csv file to find the data I am interested to analyze\n",
    "\n",
    "# I created a new dictionary here for the description column in my csv file\n",
    "descriptiondictionary = inputdata.get('Review')\n",
    "#I am converting the decription from dictionary to a list for the sentiment analyses below\n",
    "descriptionlist =  list(descriptiondictionary.values())\n",
    "\n",
    "flesch_reading_ease_results_list=[]\n",
    "gunning_fog_results_list=[]\n",
    "\n",
    "for i in range(len(descriptionlist )):\n",
    "    flesch_reading_ease_score=textstat.flesch_reading_ease(descriptionlist[i])\n",
    "    gunning_fog_score=textstat.gunning_fog(descriptionlist[i])\n",
    "    flesch_reading_ease_results_list.append(flesch_reading_ease_score)\n",
    "    gunning_fog_results_list.append(gunning_fog_score)\n",
    "\n",
    "flesch_reading_ease_results = pd.DataFrame(flesch_reading_ease_results_list)\n",
    "gunning_fog_results = pd.DataFrame(gunning_fog_results_list)\n",
    "\n",
    "file = pd.read_csv('example8results.csv')\n",
    "file['Flesch Reading Ease Score'] = flesch_reading_ease_results\n",
    "file['Gunning_Fog Score'] = gunning_fog_results\n",
    "\n",
    "#Index is false because example 8 results.csv file already has an index column\n",
    "file.to_csv('example9results.csv', index=False)\n",
    "print(\"done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Textblob Polarity Score: 0.14175000000000001\n",
      "Average Textblob Subjectivity Score: 0.1848\n",
      "Average Vader Score: 0.200874\n",
      "\n",
      "\n",
      "Minimum Textblob Polarity Score: 0.0\n",
      "Maximum Textblob Polarity Score: 1.0\n",
      "Relationship Between Textblob Polarity Score and Average Vader Compound Score PearsonRResult(statistic=0.4276985308470833, pvalue=0.0019474175537469115)\n"
     ]
    }
   ],
   "source": [
    "# Example 10\n",
    "#I am creating a dictionary here titled inputdata\n",
    "inputdata={}\n",
    "#I am assigning the content of the csv file to my dictionary\n",
    "#header is my row in the csv file that is why header is 0 below\n",
    "inputdata = pd.read_csv('example8results.csv', header=[0]).to_dict()\n",
    "\n",
    "# I created new dictionaries here\n",
    "textblobpolaritydictionary = inputdata.get('TextBlob Polarity Score')\n",
    "textblobsubjectivitydictionary = inputdata.get('TextBlob Subjectivity Score')\n",
    "vaderdictionary = inputdata.get('Vader Compound Polarity Score')\n",
    "\n",
    "#Convert the dictionaries into lists\n",
    "textblobpolaritylist= list(textblobpolaritydictionary.values())\n",
    "textblobsubjectivitylist= list(textblobsubjectivitydictionary.values())\n",
    "vaderlist= list(vaderdictionary.values())\n",
    "\n",
    "averagetextblobpolarityscore=mean(textblobpolaritylist)\n",
    "averagetextblobsubjectivityscore=mean(textblobsubjectivitylist)\n",
    "averagevaderscore=mean(vaderlist)\n",
    "\n",
    "print(\"Average Textblob Polarity Score:\", averagetextblobpolarityscore)\n",
    "print(\"Average Textblob Subjectivity Score:\", averagetextblobsubjectivityscore)\n",
    "print(\"Average Vader Score:\", averagevaderscore)\n",
    "\n",
    "minimumtextblobpolarityscore=min(textblobpolaritylist)\n",
    "maximumtextblobpolarityscore=max(textblobpolaritylist)\n",
    "\n",
    "#\\n means go to the line below in order to read printed results easier.\n",
    "print(\"\\n\")\n",
    "print(\"Minimum Textblob Polarity Score:\", minimumtextblobpolarityscore)\n",
    "print(\"Maximum Textblob Polarity Score:\", maximumtextblobpolarityscore)\n",
    "\n",
    "relationshipbetweentextblobpolarityscoreandvadercompoundscore= pearsonr(textblobpolaritylist,vaderlist)\n",
    "\n",
    "print(\"Relationship Between Textblob Polarity Score and Average Vader Compound Score\", relationshipbetweentextblobpolarityscoreandvadercompoundscore)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.9451\n",
      "0.9908\n",
      "0.200874\n",
      "0.4339426059153116\n"
     ]
    }
   ],
   "source": [
    "file = pd.read_csv('example9results.csv')\n",
    "scores = file['Vader Compound Polarity Score']\n",
    "print(scores.min())\n",
    "print(scores.max())\n",
    "print(scores.mean())\n",
    "print(scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>postTitle</th>\n",
       "      <th>postDescription</th>\n",
       "      <th>Review</th>\n",
       "      <th>likesCount</th>\n",
       "      <th>facebookUrl</th>\n",
       "      <th>TextBlob Polarity Score</th>\n",
       "      <th>TextBlob Subjectivity Score</th>\n",
       "      <th>Vader Negative Polarity Score</th>\n",
       "      <th>Vader Neutral Polarity Score</th>\n",
       "      <th>Vader Positive Polarity Score</th>\n",
       "      <th>Vader Compound Polarity Score</th>\n",
       "      <th>Flesch Reading Ease Score</th>\n",
       "      <th>Gunning_Fog Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>We know you'll fall in love with our Cookie Do...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>One of my favorites ❤️❤️❤️❤️❤️🥰🥰🥰🥰🥰</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.facebook.com/thecheesecakefactory/...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.416</td>\n",
       "      <td>0.584</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>92.80</td>\n",
       "      <td>1.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>We know you'll fall in love with our Cookie Do...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dan Combs I’ve never tried this one yet! I nee...</td>\n",
       "      <td>2</td>\n",
       "      <td>https://www.facebook.com/thecheesecakefactory/...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.722</td>\n",
       "      <td>0.278</td>\n",
       "      <td>0.9200</td>\n",
       "      <td>96.18</td>\n",
       "      <td>3.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>We know you'll fall in love with our Cookie Do...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>My favorite 🥰</td>\n",
       "      <td>1</td>\n",
       "      <td>https://www.facebook.com/thecheesecakefactory/...</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.720</td>\n",
       "      <td>0.8834</td>\n",
       "      <td>77.91</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>We know you'll fall in love with our Cookie Do...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>This looks delicious. I love cookie dough anyt...</td>\n",
       "      <td>19</td>\n",
       "      <td>https://www.facebook.com/thecheesecakefactory/...</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.582</td>\n",
       "      <td>0.418</td>\n",
       "      <td>0.8360</td>\n",
       "      <td>92.49</td>\n",
       "      <td>4.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>We know you'll fall in love with our Cookie Do...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>So delicious!!!😁</td>\n",
       "      <td>4</td>\n",
       "      <td>https://www.facebook.com/thecheesecakefactory/...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.389</td>\n",
       "      <td>0.611</td>\n",
       "      <td>0.8346</td>\n",
       "      <td>35.61</td>\n",
       "      <td>20.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>We know you'll fall in love with our Cookie Do...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ohhh Glenn!!! This looks delicious! Haha</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.facebook.com/thecheesecakefactory/...</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.337</td>\n",
       "      <td>0.663</td>\n",
       "      <td>0.8346</td>\n",
       "      <td>73.85</td>\n",
       "      <td>9.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>We know you'll fall in love with our Cookie Do...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes yes yes …🙌🏿🙌🏿🙌🏿</td>\n",
       "      <td>3</td>\n",
       "      <td>https://www.facebook.com/thecheesecakefactory/...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.664</td>\n",
       "      <td>0.336</td>\n",
       "      <td>0.7964</td>\n",
       "      <td>119.19</td>\n",
       "      <td>1.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>We know you'll fall in love with our Cookie Do...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>G.G. Garza I want you to make me some of those...</td>\n",
       "      <td>1</td>\n",
       "      <td>https://www.facebook.com/thecheesecakefactory/...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.586</td>\n",
       "      <td>0.414</td>\n",
       "      <td>0.7772</td>\n",
       "      <td>111.07</td>\n",
       "      <td>4.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>We know you'll fall in love with our Cookie Do...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>This looks amazing.  Wish I had a Cheesecake F...</td>\n",
       "      <td>2</td>\n",
       "      <td>https://www.facebook.com/thecheesecakefactory/...</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.711</td>\n",
       "      <td>0.289</td>\n",
       "      <td>0.7579</td>\n",
       "      <td>99.23</td>\n",
       "      <td>2.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>We know you'll fall in love with our Cookie Do...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>This is fantastic. Tried buying a full 10” a f...</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.facebook.com/thecheesecakefactory/...</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.772</td>\n",
       "      <td>0.228</td>\n",
       "      <td>0.7096</td>\n",
       "      <td>106.37</td>\n",
       "      <td>4.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>We know you'll fall in love with our Cookie Do...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Love it !</td>\n",
       "      <td>7</td>\n",
       "      <td>https://www.facebook.com/thecheesecakefactory/...</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.308</td>\n",
       "      <td>0.692</td>\n",
       "      <td>0.6696</td>\n",
       "      <td>120.21</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>We know you'll fall in love with our Cookie Do...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I love it ❤️</td>\n",
       "      <td>11</td>\n",
       "      <td>https://www.facebook.com/thecheesecakefactory/...</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.488</td>\n",
       "      <td>0.512</td>\n",
       "      <td>0.6369</td>\n",
       "      <td>119.19</td>\n",
       "      <td>1.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>We know you'll fall in love with our Cookie Do...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just tried it !!!! and it is now my favorite!!!!!</td>\n",
       "      <td>1</td>\n",
       "      <td>https://www.facebook.com/thecheesecakefactory/...</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.683</td>\n",
       "      <td>0.317</td>\n",
       "      <td>0.6331</td>\n",
       "      <td>109.21</td>\n",
       "      <td>1.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>We know you'll fall in love with our Cookie Do...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yummy 😋</td>\n",
       "      <td>1</td>\n",
       "      <td>https://www.facebook.com/thecheesecakefactory/...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.469</td>\n",
       "      <td>0.531</td>\n",
       "      <td>0.5267</td>\n",
       "      <td>36.62</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>We know you'll fall in love with our Cookie Do...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>So good</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.facebook.com/thecheesecakefactory/...</td>\n",
       "      <td>0.7000</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.238</td>\n",
       "      <td>0.762</td>\n",
       "      <td>0.4927</td>\n",
       "      <td>120.21</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>We know you'll fall in love with our Cookie Do...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yummmm I'm going to try this one. 😍</td>\n",
       "      <td>6</td>\n",
       "      <td>https://www.facebook.com/thecheesecakefactory/...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.769</td>\n",
       "      <td>0.231</td>\n",
       "      <td>0.4588</td>\n",
       "      <td>81.29</td>\n",
       "      <td>8.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>We know you'll fall in love with our Cookie Do...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Montrell you can eat the pecans 😂</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.facebook.com/thecheesecakefactory/...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.612</td>\n",
       "      <td>0.259</td>\n",
       "      <td>0.4404</td>\n",
       "      <td>99.23</td>\n",
       "      <td>2.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>We know you'll fall in love with our Cookie Do...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tracy Kubik I really want to try this!!</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.facebook.com/thecheesecakefactory/...</td>\n",
       "      <td>0.3125</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.763</td>\n",
       "      <td>0.237</td>\n",
       "      <td>0.2908</td>\n",
       "      <td>71.82</td>\n",
       "      <td>3.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>We know you'll fall in love with our Cookie Do...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Wish I had a cheesecake factory near me. 😕</td>\n",
       "      <td>1</td>\n",
       "      <td>https://www.facebook.com/thecheesecakefactory/...</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.177</td>\n",
       "      <td>0.615</td>\n",
       "      <td>0.208</td>\n",
       "      <td>0.1027</td>\n",
       "      <td>80.28</td>\n",
       "      <td>3.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>34</td>\n",
       "      <td>We know you'll fall in love with our Cookie Do...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sean Roberson</td>\n",
       "      <td>1</td>\n",
       "      <td>https://www.facebook.com/thecheesecakefactory/...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>77.91</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>48</td>\n",
       "      <td>We know you'll fall in love with our Cookie Do...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>David LaPlante we have to go</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.facebook.com/thecheesecakefactory/...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>99.23</td>\n",
       "      <td>2.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>46</td>\n",
       "      <td>We know you'll fall in love with our Cookie Do...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Monica Thompson Rosemary Simbeck Alicia Doerr ...</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.facebook.com/thecheesecakefactory/...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>37.30</td>\n",
       "      <td>13.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>45</td>\n",
       "      <td>We know you'll fall in love with our Cookie Do...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AJ Rowe</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.facebook.com/thecheesecakefactory/...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>120.21</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>44</td>\n",
       "      <td>We know you'll fall in love with our Cookie Do...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Matt Martinez we need to try this</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.facebook.com/thecheesecakefactory/...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>106.67</td>\n",
       "      <td>2.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>43</td>\n",
       "      <td>We know you'll fall in love with our Cookie Do...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Darius Fernandez I need this in my life</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.facebook.com/thecheesecakefactory/...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>80.28</td>\n",
       "      <td>8.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>42</td>\n",
       "      <td>We know you'll fall in love with our Cookie Do...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Patrick Turner I need this in my life real soon</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.facebook.com/thecheesecakefactory/...</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>95.17</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>41</td>\n",
       "      <td>We know you'll fall in love with our Cookie Do...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adam Seward</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.facebook.com/thecheesecakefactory/...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>77.91</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>40</td>\n",
       "      <td>We know you'll fall in love with our Cookie Do...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Allie Holmdahl</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.facebook.com/thecheesecakefactory/...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>35.61</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>39</td>\n",
       "      <td>We know you'll fall in love with our Cookie Do...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ami Wigington 🤤</td>\n",
       "      <td>1</td>\n",
       "      <td>https://www.facebook.com/thecheesecakefactory/...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>35.61</td>\n",
       "      <td>20.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>38</td>\n",
       "      <td>We know you'll fall in love with our Cookie Do...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bailee Moon</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.facebook.com/thecheesecakefactory/...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>120.21</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>37</td>\n",
       "      <td>We know you'll fall in love with our Cookie Do...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Chad Ross</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.facebook.com/thecheesecakefactory/...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>120.21</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>36</td>\n",
       "      <td>We know you'll fall in love with our Cookie Do...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Audrey Crume</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.facebook.com/thecheesecakefactory/...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>77.91</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>35</td>\n",
       "      <td>We know you'll fall in love with our Cookie Do...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Aimee D. Leyva</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.facebook.com/thecheesecakefactory/...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>93.81</td>\n",
       "      <td>1.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>33</td>\n",
       "      <td>We know you'll fall in love with our Cookie Do...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Thomas McDougal</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.facebook.com/thecheesecakefactory/...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>35.61</td>\n",
       "      <td>20.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>We know you'll fall in love with our Cookie Do...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kristie Michelle this looks incredible</td>\n",
       "      <td>1</td>\n",
       "      <td>https://www.facebook.com/thecheesecakefactory/...</td>\n",
       "      <td>0.9000</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>66.40</td>\n",
       "      <td>10.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>32</td>\n",
       "      <td>We know you'll fall in love with our Cookie Do...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Patricia Sepulveda</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.facebook.com/thecheesecakefactory/...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-49.00</td>\n",
       "      <td>40.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30</td>\n",
       "      <td>We know you'll fall in love with our Cookie Do...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>D.j. Smith</td>\n",
       "      <td>1</td>\n",
       "      <td>https://www.facebook.com/thecheesecakefactory/...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>120.21</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>We know you'll fall in love with our Cookie Do...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eugene Likens</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.facebook.com/thecheesecakefactory/...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>77.91</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>We know you'll fall in love with our Cookie Do...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Matt Roedig</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.facebook.com/thecheesecakefactory/...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>120.21</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>We know you'll fall in love with our Cookie Do...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Steve omg it’s back!!!</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.facebook.com/thecheesecakefactory/...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>118.18</td>\n",
       "      <td>1.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>We know you'll fall in love with our Cookie Do...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Coty Barnett 🤤</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.facebook.com/thecheesecakefactory/...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>35.61</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>We know you'll fall in love with our Cookie Do...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Grabbing my Birthday Slice next week !!!!!!</td>\n",
       "      <td>4</td>\n",
       "      <td>https://www.facebook.com/thecheesecakefactory/...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>90.77</td>\n",
       "      <td>2.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>We know you'll fall in love with our Cookie Do...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Christine Austin I need to try this pronto!</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.facebook.com/thecheesecakefactory/...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>88.74</td>\n",
       "      <td>3.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>We know you'll fall in love with our Cookie Do...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MaryAnne Almanzi Sauve</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.facebook.com/thecheesecakefactory/...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>93.81</td>\n",
       "      <td>1.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>We know you'll fall in love with our Cookie Do...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Lisa Burleson I absolutely need this</td>\n",
       "      <td>2</td>\n",
       "      <td>https://www.facebook.com/thecheesecakefactory/...</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>73.85</td>\n",
       "      <td>9.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>49</td>\n",
       "      <td>We know you'll fall in love with our Cookie Do...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ben Giboney I need</td>\n",
       "      <td>1</td>\n",
       "      <td>https://www.facebook.com/thecheesecakefactory/...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>92.80</td>\n",
       "      <td>1.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>We know you'll fall in love with our Cookie Do...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Foster Corley that looks 🔥</td>\n",
       "      <td>1</td>\n",
       "      <td>https://www.facebook.com/thecheesecakefactory/...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.3400</td>\n",
       "      <td>75.88</td>\n",
       "      <td>1.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31</td>\n",
       "      <td>We know you'll fall in love with our Cookie Do...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tashauna Gravely</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.facebook.com/thecheesecakefactory/...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.714</td>\n",
       "      <td>0.286</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.3612</td>\n",
       "      <td>35.61</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>47</td>\n",
       "      <td>We know you'll fall in love with our Cookie Do...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Nate Archer plz 😭😭😭😭</td>\n",
       "      <td>2</td>\n",
       "      <td>https://www.facebook.com/thecheesecakefactory/...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.523</td>\n",
       "      <td>0.422</td>\n",
       "      <td>0.055</td>\n",
       "      <td>-0.9022</td>\n",
       "      <td>119.19</td>\n",
       "      <td>1.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>We know you'll fall in love with our Cookie Do...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>🔥🔥🔥🔥🔥🔥🔥🔥</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.facebook.com/thecheesecakefactory/...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.9451</td>\n",
       "      <td>206.84</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Index                                          postTitle  postDescription  \\\n",
       "16     16  We know you'll fall in love with our Cookie Do...              NaN   \n",
       "5       5  We know you'll fall in love with our Cookie Do...              NaN   \n",
       "9       9  We know you'll fall in love with our Cookie Do...              NaN   \n",
       "0       0  We know you'll fall in love with our Cookie Do...              NaN   \n",
       "3       3  We know you'll fall in love with our Cookie Do...              NaN   \n",
       "19     19  We know you'll fall in love with our Cookie Do...              NaN   \n",
       "2       2  We know you'll fall in love with our Cookie Do...              NaN   \n",
       "15     15  We know you'll fall in love with our Cookie Do...              NaN   \n",
       "13     13  We know you'll fall in love with our Cookie Do...              NaN   \n",
       "17     17  We know you'll fall in love with our Cookie Do...              NaN   \n",
       "8       8  We know you'll fall in love with our Cookie Do...              NaN   \n",
       "4       4  We know you'll fall in love with our Cookie Do...              NaN   \n",
       "7       7  We know you'll fall in love with our Cookie Do...              NaN   \n",
       "10     10  We know you'll fall in love with our Cookie Do...              NaN   \n",
       "6       6  We know you'll fall in love with our Cookie Do...              NaN   \n",
       "12     12  We know you'll fall in love with our Cookie Do...              NaN   \n",
       "25     25  We know you'll fall in love with our Cookie Do...              NaN   \n",
       "23     23  We know you'll fall in love with our Cookie Do...              NaN   \n",
       "14     14  We know you'll fall in love with our Cookie Do...              NaN   \n",
       "34     34  We know you'll fall in love with our Cookie Do...              NaN   \n",
       "48     48  We know you'll fall in love with our Cookie Do...              NaN   \n",
       "46     46  We know you'll fall in love with our Cookie Do...              NaN   \n",
       "45     45  We know you'll fall in love with our Cookie Do...              NaN   \n",
       "44     44  We know you'll fall in love with our Cookie Do...              NaN   \n",
       "43     43  We know you'll fall in love with our Cookie Do...              NaN   \n",
       "42     42  We know you'll fall in love with our Cookie Do...              NaN   \n",
       "41     41  We know you'll fall in love with our Cookie Do...              NaN   \n",
       "40     40  We know you'll fall in love with our Cookie Do...              NaN   \n",
       "39     39  We know you'll fall in love with our Cookie Do...              NaN   \n",
       "38     38  We know you'll fall in love with our Cookie Do...              NaN   \n",
       "37     37  We know you'll fall in love with our Cookie Do...              NaN   \n",
       "36     36  We know you'll fall in love with our Cookie Do...              NaN   \n",
       "35     35  We know you'll fall in love with our Cookie Do...              NaN   \n",
       "33     33  We know you'll fall in love with our Cookie Do...              NaN   \n",
       "18     18  We know you'll fall in love with our Cookie Do...              NaN   \n",
       "32     32  We know you'll fall in love with our Cookie Do...              NaN   \n",
       "30     30  We know you'll fall in love with our Cookie Do...              NaN   \n",
       "29     29  We know you'll fall in love with our Cookie Do...              NaN   \n",
       "28     28  We know you'll fall in love with our Cookie Do...              NaN   \n",
       "27     27  We know you'll fall in love with our Cookie Do...              NaN   \n",
       "26     26  We know you'll fall in love with our Cookie Do...              NaN   \n",
       "1       1  We know you'll fall in love with our Cookie Do...              NaN   \n",
       "24     24  We know you'll fall in love with our Cookie Do...              NaN   \n",
       "21     21  We know you'll fall in love with our Cookie Do...              NaN   \n",
       "11     11  We know you'll fall in love with our Cookie Do...              NaN   \n",
       "49     49  We know you'll fall in love with our Cookie Do...              NaN   \n",
       "22     22  We know you'll fall in love with our Cookie Do...              NaN   \n",
       "31     31  We know you'll fall in love with our Cookie Do...              NaN   \n",
       "47     47  We know you'll fall in love with our Cookie Do...              NaN   \n",
       "20     20  We know you'll fall in love with our Cookie Do...              NaN   \n",
       "\n",
       "                                               Review  likesCount  \\\n",
       "16                One of my favorites ❤️❤️❤️❤️❤️🥰🥰🥰🥰🥰           0   \n",
       "5   Dan Combs I’ve never tried this one yet! I nee...           2   \n",
       "9                                       My favorite 🥰           1   \n",
       "0   This looks delicious. I love cookie dough anyt...          19   \n",
       "3                                    So delicious!!!😁           4   \n",
       "19           Ohhh Glenn!!! This looks delicious! Haha           0   \n",
       "2                                 Yes yes yes …🙌🏿🙌🏿🙌🏿           3   \n",
       "15  G.G. Garza I want you to make me some of those...           1   \n",
       "13  This looks amazing.  Wish I had a Cheesecake F...           2   \n",
       "17  This is fantastic. Tried buying a full 10” a f...           0   \n",
       "8                                           Love it !           7   \n",
       "4                                        I love it ❤️          11   \n",
       "7   Just tried it !!!! and it is now my favorite!!!!!           1   \n",
       "10                                            Yummy 😋           1   \n",
       "6                                             So good           0   \n",
       "12                Yummmm I'm going to try this one. 😍           6   \n",
       "25                  Montrell you can eat the pecans 😂           0   \n",
       "23            Tracy Kubik I really want to try this!!           0   \n",
       "14         Wish I had a cheesecake factory near me. 😕           1   \n",
       "34                                      Sean Roberson           1   \n",
       "48                       David LaPlante we have to go           0   \n",
       "46  Monica Thompson Rosemary Simbeck Alicia Doerr ...           0   \n",
       "45                                            AJ Rowe           0   \n",
       "44                  Matt Martinez we need to try this           0   \n",
       "43            Darius Fernandez I need this in my life           0   \n",
       "42    Patrick Turner I need this in my life real soon           0   \n",
       "41                                        Adam Seward           0   \n",
       "40                                     Allie Holmdahl           0   \n",
       "39                                    Ami Wigington 🤤           1   \n",
       "38                                        Bailee Moon           0   \n",
       "37                                          Chad Ross           0   \n",
       "36                                       Audrey Crume           0   \n",
       "35                                     Aimee D. Leyva           0   \n",
       "33                                    Thomas McDougal           0   \n",
       "18             Kristie Michelle this looks incredible           1   \n",
       "32                                 Patricia Sepulveda           0   \n",
       "30                                         D.j. Smith           1   \n",
       "29                                      Eugene Likens           0   \n",
       "28                                        Matt Roedig           0   \n",
       "27                             Steve omg it’s back!!!           0   \n",
       "26                                     Coty Barnett 🤤           0   \n",
       "1         Grabbing my Birthday Slice next week !!!!!!           4   \n",
       "24        Christine Austin I need to try this pronto!           0   \n",
       "21                             MaryAnne Almanzi Sauve           0   \n",
       "11               Lisa Burleson I absolutely need this           2   \n",
       "49                                 Ben Giboney I need           1   \n",
       "22                         Foster Corley that looks 🔥           1   \n",
       "31                                   Tashauna Gravely           0   \n",
       "47                               Nate Archer plz 😭😭😭😭           2   \n",
       "20                                           🔥🔥🔥🔥🔥🔥🔥🔥           0   \n",
       "\n",
       "                                          facebookUrl  \\\n",
       "16  https://www.facebook.com/thecheesecakefactory/...   \n",
       "5   https://www.facebook.com/thecheesecakefactory/...   \n",
       "9   https://www.facebook.com/thecheesecakefactory/...   \n",
       "0   https://www.facebook.com/thecheesecakefactory/...   \n",
       "3   https://www.facebook.com/thecheesecakefactory/...   \n",
       "19  https://www.facebook.com/thecheesecakefactory/...   \n",
       "2   https://www.facebook.com/thecheesecakefactory/...   \n",
       "15  https://www.facebook.com/thecheesecakefactory/...   \n",
       "13  https://www.facebook.com/thecheesecakefactory/...   \n",
       "17  https://www.facebook.com/thecheesecakefactory/...   \n",
       "8   https://www.facebook.com/thecheesecakefactory/...   \n",
       "4   https://www.facebook.com/thecheesecakefactory/...   \n",
       "7   https://www.facebook.com/thecheesecakefactory/...   \n",
       "10  https://www.facebook.com/thecheesecakefactory/...   \n",
       "6   https://www.facebook.com/thecheesecakefactory/...   \n",
       "12  https://www.facebook.com/thecheesecakefactory/...   \n",
       "25  https://www.facebook.com/thecheesecakefactory/...   \n",
       "23  https://www.facebook.com/thecheesecakefactory/...   \n",
       "14  https://www.facebook.com/thecheesecakefactory/...   \n",
       "34  https://www.facebook.com/thecheesecakefactory/...   \n",
       "48  https://www.facebook.com/thecheesecakefactory/...   \n",
       "46  https://www.facebook.com/thecheesecakefactory/...   \n",
       "45  https://www.facebook.com/thecheesecakefactory/...   \n",
       "44  https://www.facebook.com/thecheesecakefactory/...   \n",
       "43  https://www.facebook.com/thecheesecakefactory/...   \n",
       "42  https://www.facebook.com/thecheesecakefactory/...   \n",
       "41  https://www.facebook.com/thecheesecakefactory/...   \n",
       "40  https://www.facebook.com/thecheesecakefactory/...   \n",
       "39  https://www.facebook.com/thecheesecakefactory/...   \n",
       "38  https://www.facebook.com/thecheesecakefactory/...   \n",
       "37  https://www.facebook.com/thecheesecakefactory/...   \n",
       "36  https://www.facebook.com/thecheesecakefactory/...   \n",
       "35  https://www.facebook.com/thecheesecakefactory/...   \n",
       "33  https://www.facebook.com/thecheesecakefactory/...   \n",
       "18  https://www.facebook.com/thecheesecakefactory/...   \n",
       "32  https://www.facebook.com/thecheesecakefactory/...   \n",
       "30  https://www.facebook.com/thecheesecakefactory/...   \n",
       "29  https://www.facebook.com/thecheesecakefactory/...   \n",
       "28  https://www.facebook.com/thecheesecakefactory/...   \n",
       "27  https://www.facebook.com/thecheesecakefactory/...   \n",
       "26  https://www.facebook.com/thecheesecakefactory/...   \n",
       "1   https://www.facebook.com/thecheesecakefactory/...   \n",
       "24  https://www.facebook.com/thecheesecakefactory/...   \n",
       "21  https://www.facebook.com/thecheesecakefactory/...   \n",
       "11  https://www.facebook.com/thecheesecakefactory/...   \n",
       "49  https://www.facebook.com/thecheesecakefactory/...   \n",
       "22  https://www.facebook.com/thecheesecakefactory/...   \n",
       "31  https://www.facebook.com/thecheesecakefactory/...   \n",
       "47  https://www.facebook.com/thecheesecakefactory/...   \n",
       "20  https://www.facebook.com/thecheesecakefactory/...   \n",
       "\n",
       "    TextBlob Polarity Score  TextBlob Subjectivity Score  \\\n",
       "16                   0.0000                         0.00   \n",
       "5                    0.0000                         0.00   \n",
       "9                    0.5000                         1.00   \n",
       "0                    0.7500                         0.80   \n",
       "3                    0.0000                         0.00   \n",
       "19                   0.6000                         0.65   \n",
       "2                    0.0000                         0.00   \n",
       "15                   0.0000                         0.00   \n",
       "13                   0.6000                         0.90   \n",
       "17                   0.1000                         0.39   \n",
       "8                    0.6250                         0.60   \n",
       "4                    0.5000                         0.60   \n",
       "7                    1.0000                         1.00   \n",
       "10                   0.0000                         0.00   \n",
       "6                    0.7000                         0.60   \n",
       "12                   0.0000                         0.00   \n",
       "25                   0.0000                         0.00   \n",
       "23                   0.3125                         0.20   \n",
       "14                   0.1000                         0.40   \n",
       "34                   0.0000                         0.00   \n",
       "48                   0.0000                         0.00   \n",
       "46                   0.0000                         0.00   \n",
       "45                   0.0000                         0.00   \n",
       "44                   0.0000                         0.00   \n",
       "43                   0.0000                         0.00   \n",
       "42                   0.2000                         0.30   \n",
       "41                   0.0000                         0.00   \n",
       "40                   0.0000                         0.00   \n",
       "39                   0.0000                         0.00   \n",
       "38                   0.0000                         0.00   \n",
       "37                   0.0000                         0.00   \n",
       "36                   0.0000                         0.00   \n",
       "35                   0.0000                         0.00   \n",
       "33                   0.0000                         0.00   \n",
       "18                   0.9000                         0.90   \n",
       "32                   0.0000                         0.00   \n",
       "30                   0.0000                         0.00   \n",
       "29                   0.0000                         0.00   \n",
       "28                   0.0000                         0.00   \n",
       "27                   0.0000                         0.00   \n",
       "26                   0.0000                         0.00   \n",
       "1                    0.0000                         0.00   \n",
       "24                   0.0000                         0.00   \n",
       "21                   0.0000                         0.00   \n",
       "11                   0.2000                         0.90   \n",
       "49                   0.0000                         0.00   \n",
       "22                   0.0000                         0.00   \n",
       "31                   0.0000                         0.00   \n",
       "47                   0.0000                         0.00   \n",
       "20                   0.0000                         0.00   \n",
       "\n",
       "    Vader Negative Polarity Score  Vader Neutral Polarity Score  \\\n",
       "16                          0.000                         0.416   \n",
       "5                           0.000                         0.722   \n",
       "9                           0.000                         0.280   \n",
       "0                           0.000                         0.582   \n",
       "3                           0.000                         0.389   \n",
       "19                          0.000                         0.337   \n",
       "2                           0.000                         0.664   \n",
       "15                          0.000                         0.586   \n",
       "13                          0.000                         0.711   \n",
       "17                          0.000                         0.772   \n",
       "8                           0.000                         0.308   \n",
       "4                           0.000                         0.488   \n",
       "7                           0.000                         0.683   \n",
       "10                          0.000                         0.469   \n",
       "6                           0.000                         0.238   \n",
       "12                          0.000                         0.769   \n",
       "25                          0.129                         0.612   \n",
       "23                          0.000                         0.763   \n",
       "14                          0.177                         0.615   \n",
       "34                          0.000                         1.000   \n",
       "48                          0.000                         1.000   \n",
       "46                          0.000                         1.000   \n",
       "45                          0.000                         1.000   \n",
       "44                          0.000                         1.000   \n",
       "43                          0.000                         1.000   \n",
       "42                          0.000                         1.000   \n",
       "41                          0.000                         1.000   \n",
       "40                          0.000                         1.000   \n",
       "39                          0.000                         1.000   \n",
       "38                          0.000                         1.000   \n",
       "37                          0.000                         1.000   \n",
       "36                          0.000                         1.000   \n",
       "35                          0.000                         1.000   \n",
       "33                          0.000                         1.000   \n",
       "18                          0.000                         1.000   \n",
       "32                          0.000                         1.000   \n",
       "30                          0.000                         1.000   \n",
       "29                          0.000                         1.000   \n",
       "28                          0.000                         1.000   \n",
       "27                          0.000                         1.000   \n",
       "26                          0.000                         1.000   \n",
       "1                           0.000                         1.000   \n",
       "24                          0.000                         1.000   \n",
       "21                          0.000                         1.000   \n",
       "11                          0.000                         1.000   \n",
       "49                          0.000                         1.000   \n",
       "22                          0.375                         0.625   \n",
       "31                          0.714                         0.286   \n",
       "47                          0.523                         0.422   \n",
       "20                          1.000                         0.000   \n",
       "\n",
       "    Vader Positive Polarity Score  Vader Compound Polarity Score  \\\n",
       "16                          0.584                         0.9908   \n",
       "5                           0.278                         0.9200   \n",
       "9                           0.720                         0.8834   \n",
       "0                           0.418                         0.8360   \n",
       "3                           0.611                         0.8346   \n",
       "19                          0.663                         0.8346   \n",
       "2                           0.336                         0.7964   \n",
       "15                          0.414                         0.7772   \n",
       "13                          0.289                         0.7579   \n",
       "17                          0.228                         0.7096   \n",
       "8                           0.692                         0.6696   \n",
       "4                           0.512                         0.6369   \n",
       "7                           0.317                         0.6331   \n",
       "10                          0.531                         0.5267   \n",
       "6                           0.762                         0.4927   \n",
       "12                          0.231                         0.4588   \n",
       "25                          0.259                         0.4404   \n",
       "23                          0.237                         0.2908   \n",
       "14                          0.208                         0.1027   \n",
       "34                          0.000                         0.0000   \n",
       "48                          0.000                         0.0000   \n",
       "46                          0.000                         0.0000   \n",
       "45                          0.000                         0.0000   \n",
       "44                          0.000                         0.0000   \n",
       "43                          0.000                         0.0000   \n",
       "42                          0.000                         0.0000   \n",
       "41                          0.000                         0.0000   \n",
       "40                          0.000                         0.0000   \n",
       "39                          0.000                         0.0000   \n",
       "38                          0.000                         0.0000   \n",
       "37                          0.000                         0.0000   \n",
       "36                          0.000                         0.0000   \n",
       "35                          0.000                         0.0000   \n",
       "33                          0.000                         0.0000   \n",
       "18                          0.000                         0.0000   \n",
       "32                          0.000                         0.0000   \n",
       "30                          0.000                         0.0000   \n",
       "29                          0.000                         0.0000   \n",
       "28                          0.000                         0.0000   \n",
       "27                          0.000                         0.0000   \n",
       "26                          0.000                         0.0000   \n",
       "1                           0.000                         0.0000   \n",
       "24                          0.000                         0.0000   \n",
       "21                          0.000                         0.0000   \n",
       "11                          0.000                         0.0000   \n",
       "49                          0.000                         0.0000   \n",
       "22                          0.000                        -0.3400   \n",
       "31                          0.000                        -0.3612   \n",
       "47                          0.055                        -0.9022   \n",
       "20                          0.000                        -0.9451   \n",
       "\n",
       "    Flesch Reading Ease Score  Gunning_Fog Score  \n",
       "16                      92.80               1.60  \n",
       "5                       96.18               3.60  \n",
       "9                       77.91               0.80  \n",
       "0                       92.49               4.80  \n",
       "3                       35.61              20.80  \n",
       "19                      73.85               9.07  \n",
       "2                      119.19               1.20  \n",
       "15                     111.07               4.40  \n",
       "13                      99.23               2.40  \n",
       "17                     106.37               4.74  \n",
       "8                      120.21               0.80  \n",
       "4                      119.19               1.20  \n",
       "7                      109.21               1.80  \n",
       "10                      36.62               0.40  \n",
       "6                      120.21               0.80  \n",
       "12                      81.29               8.51  \n",
       "25                      99.23               2.40  \n",
       "23                      71.82               3.20  \n",
       "14                      80.28               3.20  \n",
       "34                      77.91               0.80  \n",
       "48                      99.23               2.40  \n",
       "46                      37.30              13.86  \n",
       "45                     120.21               0.80  \n",
       "44                     106.67               2.80  \n",
       "43                      80.28               8.20  \n",
       "42                      95.17               4.00  \n",
       "41                      77.91               0.80  \n",
       "40                      35.61               0.80  \n",
       "39                      35.61              20.80  \n",
       "38                     120.21               0.80  \n",
       "37                     120.21               0.80  \n",
       "36                      77.91               0.80  \n",
       "35                      93.81               1.20  \n",
       "33                      35.61              20.80  \n",
       "18                      66.40              10.00  \n",
       "32                     -49.00              40.80  \n",
       "30                     120.21               0.80  \n",
       "29                      77.91               0.80  \n",
       "28                     120.21               0.80  \n",
       "27                     118.18               1.60  \n",
       "26                      35.61               0.80  \n",
       "1                       90.77               2.40  \n",
       "24                      88.74               3.20  \n",
       "21                      93.81               1.20  \n",
       "11                      73.85               9.07  \n",
       "49                      92.80               1.60  \n",
       "22                      75.88               1.60  \n",
       "31                      35.61               0.80  \n",
       "47                     119.19               1.20  \n",
       "20                     206.84               0.00  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file.sort_values(by='Vader Compound Polarity Score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'title'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Sam\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3790\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3789\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3790\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[0;32m   3791\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:152\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:181\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'title'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32me:\\Aliit\\School\\MSBA\\212\\Git\\MSBA-212\\Classwork\\Week 3.ipynb Cell 11\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/Aliit/School/MSBA/212/Git/MSBA-212/Classwork/Week%203.ipynb#X13sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m charPinTitle \u001b[39m=\u001b[39m []\n\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/Aliit/School/MSBA/212/Git/MSBA-212/Classwork/Week%203.ipynb#X13sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m file[\u001b[39m'\u001b[39;49m\u001b[39mtitle\u001b[39;49m\u001b[39m'\u001b[39;49m]:\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/Aliit/School/MSBA/212/Git/MSBA-212/Classwork/Week%203.ipynb#X13sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     charPinTitle\u001b[39m.\u001b[39mappend(\u001b[39msum\u001b[39m(\u001b[39mnot\u001b[39;00m \u001b[39mchr\u001b[39m\u001b[39m.\u001b[39misspace() \u001b[39mfor\u001b[39;00m \u001b[39mchr\u001b[39m \u001b[39min\u001b[39;00m x))\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/Aliit/School/MSBA/212/Git/MSBA-212/Classwork/Week%203.ipynb#X13sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m file\u001b[39m.\u001b[39minsert(\u001b[39m4\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mcharPinTitle\u001b[39m\u001b[39m'\u001b[39m, charPinTitle)\n",
      "File \u001b[1;32mc:\\Users\\Sam\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py:3896\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3894\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   3895\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3896\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[0;32m   3897\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3898\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\Sam\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3797\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3792\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(casted_key, \u001b[39mslice\u001b[39m) \u001b[39mor\u001b[39;00m (\n\u001b[0;32m   3793\u001b[0m         \u001b[39misinstance\u001b[39m(casted_key, abc\u001b[39m.\u001b[39mIterable)\n\u001b[0;32m   3794\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39many\u001b[39m(\u001b[39misinstance\u001b[39m(x, \u001b[39mslice\u001b[39m) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m casted_key)\n\u001b[0;32m   3795\u001b[0m     ):\n\u001b[0;32m   3796\u001b[0m         \u001b[39mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3797\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   3798\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m   3799\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3800\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3801\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3802\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'title'"
     ]
    }
   ],
   "source": [
    "charPinTitle = []\n",
    "for x in file['title']:\n",
    "    charPinTitle.append(sum(not chr.isspace() for chr in x))\n",
    "file.insert(4, 'charPinTitle', charPinTitle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>search_keyword</th>\n",
       "      <th>url</th>\n",
       "      <th>name</th>\n",
       "      <th>charPinTitle</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>TextBlob Polarity Score</th>\n",
       "      <th>TextBlob Subjectivity Score</th>\n",
       "      <th>Vader Negative Polarity Score</th>\n",
       "      <th>Vader Neutral Polarity Score</th>\n",
       "      <th>Vader Positive Polarity Score</th>\n",
       "      <th>Vader Compound Polarity Score</th>\n",
       "      <th>Flesch Reading Ease Score</th>\n",
       "      <th>Gunning_Fog Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>tim gunn</td>\n",
       "      <td>https://i.pinimg.com/474x/ae/4f/70/ae4f70989fb...</td>\n",
       "      <td>ae4f70989fbd1a3838c0b539b10a2204--tim-gunn-veg...</td>\n",
       "      <td>34</td>\n",
       "      <td>Tim Gunn xox: A fashion show at Stanford.</td>\n",
       "      <td>One of the coolest things about living in the ...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.884</td>\n",
       "      <td>0.116</td>\n",
       "      <td>0.5859</td>\n",
       "      <td>59.98</td>\n",
       "      <td>12.63</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Index search_keyword                                                url  \\\n",
       "0      0       tim gunn  https://i.pinimg.com/474x/ae/4f/70/ae4f70989fb...   \n",
       "\n",
       "                                                name  charPinTitle  \\\n",
       "0  ae4f70989fbd1a3838c0b539b10a2204--tim-gunn-veg...            34   \n",
       "\n",
       "                                       title  \\\n",
       "0  Tim Gunn xox: A fashion show at Stanford.   \n",
       "\n",
       "                                         description  TextBlob Polarity Score  \\\n",
       "0  One of the coolest things about living in the ...                      0.5   \n",
       "\n",
       "   TextBlob Subjectivity Score  Vader Negative Polarity Score  \\\n",
       "0                        0.625                            0.0   \n",
       "\n",
       "   Vader Neutral Polarity Score  Vader Positive Polarity Score  \\\n",
       "0                         0.884                          0.116   \n",
       "\n",
       "   Vader Compound Polarity Score  Flesch Reading Ease Score  Gunning_Fog Score  \n",
       "0                         0.5859                      59.98              12.63  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "charPinDesc = []\n",
    "for x in file['description']:\n",
    "    charPinDesc.append(sum(not chr.isspace() for chr in x))\n",
    "file.insert(6, 'charPinDesc', charPinDesc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "45.84615384615385\n",
      "91\n",
      "23.856913837674398\n"
     ]
    }
   ],
   "source": [
    "print(file['charPinTitle'].min())\n",
    "print(file['charPinTitle'].mean())\n",
    "print(file['charPinTitle'].max())\n",
    "print(file['charPinTitle'].std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "139.1153846153846\n",
      "415\n",
      "106.86745571971869\n"
     ]
    }
   ],
   "source": [
    "print(file['charPinDesc'].min())\n",
    "print(file['charPinDesc'].mean())\n",
    "print(file['charPinDesc'].max())\n",
    "print(file['charPinDesc'].std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    -0.3875\n",
       "30   -0.3875\n",
       "21   -0.3182\n",
       "47   -0.3182\n",
       "45    0.0000\n",
       "32    0.0000\n",
       "22    0.0000\n",
       "19    0.0000\n",
       "33    0.0000\n",
       "15    0.0000\n",
       "36    0.0000\n",
       "29    0.0000\n",
       "48    0.0000\n",
       "7     0.0000\n",
       "6     0.0000\n",
       "10    0.0000\n",
       "3     0.0000\n",
       "41    0.0000\n",
       "16    0.0258\n",
       "42    0.0258\n",
       "27    0.1513\n",
       "1     0.1513\n",
       "20    0.3182\n",
       "46    0.3182\n",
       "13    0.3612\n",
       "39    0.3612\n",
       "14    0.4215\n",
       "40    0.4215\n",
       "18    0.4728\n",
       "44    0.4728\n",
       "0     0.5859\n",
       "26    0.5859\n",
       "17    0.6369\n",
       "43    0.6369\n",
       "11    0.7003\n",
       "37    0.7003\n",
       "2     0.7184\n",
       "28    0.7184\n",
       "12    0.7514\n",
       "38    0.7514\n",
       "34    0.7717\n",
       "8     0.7717\n",
       "23    0.7933\n",
       "49    0.7933\n",
       "25    0.8356\n",
       "31    0.8356\n",
       "5     0.8356\n",
       "51    0.8356\n",
       "50    0.8516\n",
       "24    0.8516\n",
       "9     0.9670\n",
       "35    0.9670\n",
       "Name: Vader Compound Polarity Score, dtype: float64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file['Vader Compound Polarity Score'].sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>search_keyword</th>\n",
       "      <th>url</th>\n",
       "      <th>name</th>\n",
       "      <th>charPinTitle</th>\n",
       "      <th>title</th>\n",
       "      <th>charPinDesc</th>\n",
       "      <th>description</th>\n",
       "      <th>TextBlob Polarity Score</th>\n",
       "      <th>TextBlob Subjectivity Score</th>\n",
       "      <th>Vader Negative Polarity Score</th>\n",
       "      <th>Vader Neutral Polarity Score</th>\n",
       "      <th>Vader Positive Polarity Score</th>\n",
       "      <th>Vader Compound Polarity Score</th>\n",
       "      <th>Flesch Reading Ease Score</th>\n",
       "      <th>Gunning_Fog Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>35</td>\n",
       "      <td>tim gunn</td>\n",
       "      <td>https://i.pinimg.com/474x/d0/11/84/d01184dd984...</td>\n",
       "      <td>d01184dd984728319cefd86e08cfe11c--project-runw...</td>\n",
       "      <td>14</td>\n",
       "      <td>The Wedding Gown</td>\n",
       "      <td>415</td>\n",
       "      <td>Project Runway Bridal Gown Inspiration \"Projec...</td>\n",
       "      <td>0.25625</td>\n",
       "      <td>0.50625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.967</td>\n",
       "      <td>62.88</td>\n",
       "      <td>11.48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Index search_keyword                                                url  \\\n",
       "35     35       tim gunn  https://i.pinimg.com/474x/d0/11/84/d01184dd984...   \n",
       "\n",
       "                                                 name  charPinTitle  \\\n",
       "35  d01184dd984728319cefd86e08cfe11c--project-runw...            14   \n",
       "\n",
       "               title  charPinDesc  \\\n",
       "35  The Wedding Gown          415   \n",
       "\n",
       "                                          description  \\\n",
       "35  Project Runway Bridal Gown Inspiration \"Projec...   \n",
       "\n",
       "    TextBlob Polarity Score  TextBlob Subjectivity Score  \\\n",
       "35                  0.25625                      0.50625   \n",
       "\n",
       "    Vader Negative Polarity Score  Vader Neutral Polarity Score  \\\n",
       "35                            0.0                          0.79   \n",
       "\n",
       "    Vader Positive Polarity Score  Vader Compound Polarity Score  \\\n",
       "35                           0.21                          0.967   \n",
       "\n",
       "    Flesch Reading Ease Score  Gunning_Fog Score  \n",
       "35                      62.88              11.48  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file.loc[[35]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Index search_keyword                                                url  \\\n",
      "35     35       tim gunn  https://i.pinimg.com/474x/d0/11/84/d01184dd984...   \n",
      "\n",
      "                                                 name  charPinTitle  \\\n",
      "35  d01184dd984728319cefd86e08cfe11c--project-runw...            14   \n",
      "\n",
      "               title  charPinDesc  \\\n",
      "35  The Wedding Gown          415   \n",
      "\n",
      "                                          description  \\\n",
      "35  Project Runway Bridal Gown Inspiration \"Projec...   \n",
      "\n",
      "    TextBlob Polarity Score  TextBlob Subjectivity Score  \\\n",
      "35                  0.25625                      0.50625   \n",
      "\n",
      "    Vader Negative Polarity Score  Vader Neutral Polarity Score  \\\n",
      "35                            0.0                          0.79   \n",
      "\n",
      "    Vader Positive Polarity Score  Vader Compound Polarity Score  \\\n",
      "35                           0.21                          0.967   \n",
      "\n",
      "    Flesch Reading Ease Score  Gunning_Fog Score  \n",
      "35                      62.88              11.48  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to c:\\Users\\Sam\\AppData\\Loca\n",
      "[nltk_data]     l\\Programs\\Python\\Python311\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Common Description Unigrams: [(('.',), 4), (('project',), 3), (('runway',), 3)]\n",
      "Most Common Title Unigrams: [(('wedding',), 1), (('gown',), 1)]\n",
      "Most Common Description Bigrams: [(('project', 'runway'), 3), (('runway', 'bridal'), 1), (('bridal', 'gown'), 1)]\n",
      "Most Common Title Biigrams: [(('wedding', 'gown'), 1)]\n",
      "Most Common Description Trigrams: [(('project', 'runway', 'bridal'), 1), (('runway', 'bridal', 'gown'), 1), (('bridal', 'gown', 'inspiration'), 1)]\n",
      "Most Common Title Trigrams: []\n"
     ]
    }
   ],
   "source": [
    "# Example 7\n",
    "#I am creating a dictionary here titled inputdata\n",
    "inputdata={}\n",
    "#I am assigning the content of the csv file to my dictionary\n",
    "#header is my row in the csv file that is why header is 0 below\n",
    "inputdata = file.loc[[35]]\n",
    "print(inputdata)\n",
    "#We can use type to check the data type of a variable\n",
    "#print(type(inputdata))\n",
    "\n",
    "#I am using the column headers from the csv file to find the data I am interested to analyze\n",
    "\n",
    "# I created a new dictionary here for the description column in my csv file\n",
    "titledictionary = inputdata.get('title')\n",
    "descriptiondictionary = inputdata.get('description')\n",
    "\n",
    "\n",
    "# I am converting the dictionary to a list so I can analyze the data\n",
    "titlelist = titledictionary\n",
    "descriptionlist =  descriptiondictionary\n",
    "\n",
    "\n",
    "#convert list to string\n",
    "#I need the data in string format for analysis purposes\n",
    "titleinstring = ''\n",
    "for eachtitleletter in  titlelist:\n",
    "    titleinstring += ' '+ eachtitleletter\n",
    "\n",
    "descriptioninstring = ''\n",
    "for eachdescriptionletter in  descriptionlist:\n",
    "    descriptioninstring += ' '+ eachdescriptionletter\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.util import ngrams\n",
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "\n",
    "#Access to the string from the previous file and make the string lower case\n",
    "lowercasedescriptions=descriptioninstring.lower()\n",
    "lowercasetitles=titleinstring.lower()\n",
    "\n",
    "#remove the url from text to prevent a future error\n",
    "lowercasedescriptions= re.sub(r'\\w+:\\/{2}[\\d\\w-]+(\\.[\\d\\w-]+)*(?:(?:\\/[^\\s/]*))*', '', lowercasedescriptions)\n",
    "lowercasetitles= re.sub(r'\\w+:\\/{2}[\\d\\w-]+(\\.[\\d\\w-]+)*(?:(?:\\/[^\\s/]*))*', '', lowercasetitles)\n",
    "#print(lowercasedescriptions)\n",
    "\n",
    "#remove the stop or common words from the string\n",
    "nltk.download('stopwords')\n",
    "#print(stopwords.words('english'))\n",
    "\n",
    "description_tokens = word_tokenize(lowercasedescriptions)\n",
    "title_tokens = word_tokenize(lowercasetitles)\n",
    "\n",
    "description_tokens_without_stopwords = [word for word in description_tokens if not word in stopwords.words()]\n",
    "\n",
    "title_tokens_without_stopwords = [word for word in title_tokens if not word in stopwords.words()]\n",
    "\n",
    "#print(description_tokens_without_stopwords )\n",
    "\n",
    "descriptionunigrams = ngrams(description_tokens_without_stopwords, 1)\n",
    "descriptionbigrams = ngrams(description_tokens_without_stopwords,2)\n",
    "descriptiontrigrams = ngrams(description_tokens_without_stopwords,3)\n",
    "\n",
    "titleunigrams = ngrams(title_tokens_without_stopwords, 1)\n",
    "titlebigrams = ngrams(title_tokens_without_stopwords,2)\n",
    "titletrigrams = ngrams(title_tokens_without_stopwords,3)\n",
    "\n",
    "#print (Counter(unigrams))\n",
    "#print (Counter(bigrams))\n",
    "#print (Counter(trigrams))\n",
    "\n",
    "mostcommondescriptionunigrams = Counter(descriptionunigrams)\n",
    "mostcommontitleunigrams = Counter(titleunigrams)\n",
    "#This will print top 3 unigrams\n",
    "print(\"Most Common Description Unigrams:\", mostcommondescriptionunigrams.most_common(3))\n",
    "print(\"Most Common Title Unigrams:\",mostcommontitleunigrams.most_common(3))\n",
    "\n",
    "mostcommondescriptionbigrams = Counter(descriptionbigrams)\n",
    "mostcommontitlebigrams = Counter(titlebigrams)\n",
    "print(\"Most Common Description Bigrams:\",mostcommondescriptionbigrams.most_common(3))\n",
    "print(\"Most Common Title Biigrams:\",mostcommontitlebigrams.most_common(3))\n",
    "\n",
    "mostcommondescriptiontrigrams = Counter(descriptiontrigrams)\n",
    "mostcommontitletrigrams = Counter(titletrigrams)\n",
    "print(\"Most Common Description Trigrams:\",mostcommondescriptiontrigrams.most_common(3))\n",
    "print(\"Most Common Title Trigrams:\",mostcommontitletrigrams.most_common(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Index search_keyword                                                url  \\\n",
      "4      4       tim gunn  https://i.pinimg.com/474x/2e/9b/dd/2e9bdd53924...   \n",
      "\n",
      "                                                name  charPinTitle  \\\n",
      "4  2e9bdd5392497d37e499a005b6a131cb--plus-size-mo...            72   \n",
      "\n",
      "                                               title  charPinDesc  \\\n",
      "4  First look: Project Runway's Ashley Nell Tipto...           46   \n",
      "\n",
      "                                         description  TextBlob Polarity Score  \\\n",
      "4  And she doesn't care what you call it, as long...                    -0.05   \n",
      "\n",
      "   TextBlob Subjectivity Score  Vader Negative Polarity Score  \\\n",
      "4                          0.4                           0.18   \n",
      "\n",
      "   Vader Neutral Polarity Score  Vader Positive Polarity Score  \\\n",
      "4                          0.82                            0.0   \n",
      "\n",
      "   Vader Compound Polarity Score  Flesch Reading Ease Score  Gunning_Fog Score  \n",
      "4                        -0.3875                     100.58                5.2  \n",
      "Most Common Description Unigrams: [((\"n't\",), 1), (('call',), 1), ((',',), 1)]\n",
      "Most Common Title Unigrams: [((':',), 1), (('project',), 1), (('runway',), 1)]\n",
      "Most Common Description Bigrams: [((\"n't\", 'call'), 1), (('call', ','), 1), ((',', 'long'), 1)]\n",
      "Most Common Title Biigrams: [((':', 'project'), 1), (('project', 'runway'), 1), (('runway', \"'s\"), 1)]\n",
      "Most Common Description Trigrams: [((\"n't\", 'call', ','), 1), (('call', ',', 'long'), 1), ((',', 'long', 'fits'), 1)]\n",
      "Most Common Title Trigrams: [((':', 'project', 'runway'), 1), (('project', 'runway', \"'s\"), 1), (('runway', \"'s\", 'ashley'), 1)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to c:\\Users\\Sam\\AppData\\Loca\n",
      "[nltk_data]     l\\Programs\\Python\\Python311\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Example 7\n",
    "#I am creating a dictionary here titled inputdata\n",
    "inputdata={}\n",
    "#I am assigning the content of the csv file to my dictionary\n",
    "#header is my row in the csv file that is why header is 0 below\n",
    "inputdata = file.loc[[4]]\n",
    "print(inputdata)\n",
    "#We can use type to check the data type of a variable\n",
    "#print(type(inputdata))\n",
    "\n",
    "#I am using the column headers from the csv file to find the data I am interested to analyze\n",
    "\n",
    "# I created a new dictionary here for the description column in my csv file\n",
    "titledictionary = inputdata.get('title')\n",
    "descriptiondictionary = inputdata.get('description')\n",
    "\n",
    "\n",
    "# I am converting the dictionary to a list so I can analyze the data\n",
    "titlelist = titledictionary\n",
    "descriptionlist =  descriptiondictionary\n",
    "\n",
    "\n",
    "#convert list to string\n",
    "#I need the data in string format for analysis purposes\n",
    "titleinstring = ''\n",
    "for eachtitleletter in  titlelist:\n",
    "    titleinstring += ' '+ eachtitleletter\n",
    "\n",
    "descriptioninstring = ''\n",
    "for eachdescriptionletter in  descriptionlist:\n",
    "    descriptioninstring += ' '+ eachdescriptionletter\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.util import ngrams\n",
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "\n",
    "#Access to the string from the previous file and make the string lower case\n",
    "lowercasedescriptions=descriptioninstring.lower()\n",
    "lowercasetitles=titleinstring.lower()\n",
    "\n",
    "#remove the url from text to prevent a future error\n",
    "lowercasedescriptions= re.sub(r'\\w+:\\/{2}[\\d\\w-]+(\\.[\\d\\w-]+)*(?:(?:\\/[^\\s/]*))*', '', lowercasedescriptions)\n",
    "lowercasetitles= re.sub(r'\\w+:\\/{2}[\\d\\w-]+(\\.[\\d\\w-]+)*(?:(?:\\/[^\\s/]*))*', '', lowercasetitles)\n",
    "#print(lowercasedescriptions)\n",
    "\n",
    "#remove the stop or common words from the string\n",
    "nltk.download('stopwords')\n",
    "#print(stopwords.words('english'))\n",
    "\n",
    "description_tokens = word_tokenize(lowercasedescriptions)\n",
    "title_tokens = word_tokenize(lowercasetitles)\n",
    "\n",
    "description_tokens_without_stopwords = [word for word in description_tokens if not word in stopwords.words()]\n",
    "\n",
    "title_tokens_without_stopwords = [word for word in title_tokens if not word in stopwords.words()]\n",
    "\n",
    "#print(description_tokens_without_stopwords )\n",
    "\n",
    "descriptionunigrams = ngrams(description_tokens_without_stopwords, 1)\n",
    "descriptionbigrams = ngrams(description_tokens_without_stopwords,2)\n",
    "descriptiontrigrams = ngrams(description_tokens_without_stopwords,3)\n",
    "\n",
    "titleunigrams = ngrams(title_tokens_without_stopwords, 1)\n",
    "titlebigrams = ngrams(title_tokens_without_stopwords,2)\n",
    "titletrigrams = ngrams(title_tokens_without_stopwords,3)\n",
    "\n",
    "#print (Counter(unigrams))\n",
    "#print (Counter(bigrams))\n",
    "#print (Counter(trigrams))\n",
    "\n",
    "mostcommondescriptionunigrams = Counter(descriptionunigrams)\n",
    "mostcommontitleunigrams = Counter(titleunigrams)\n",
    "#This will print top 3 unigrams\n",
    "print(\"Most Common Description Unigrams:\", mostcommondescriptionunigrams.most_common(3))\n",
    "print(\"Most Common Title Unigrams:\",mostcommontitleunigrams.most_common(3))\n",
    "\n",
    "mostcommondescriptionbigrams = Counter(descriptionbigrams)\n",
    "mostcommontitlebigrams = Counter(titlebigrams)\n",
    "print(\"Most Common Description Bigrams:\",mostcommondescriptionbigrams.most_common(3))\n",
    "print(\"Most Common Title Biigrams:\",mostcommontitlebigrams.most_common(3))\n",
    "\n",
    "mostcommondescriptiontrigrams = Counter(descriptiontrigrams)\n",
    "mostcommontitletrigrams = Counter(titletrigrams)\n",
    "print(\"Most Common Description Trigrams:\",mostcommondescriptiontrigrams.most_common(3))\n",
    "print(\"Most Common Title Trigrams:\",mostcommontitletrigrams.most_common(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4\n",
      "8.415384615384614\n",
      "18.56\n",
      "4.21439478200396\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "41     0.40\n",
       "15     0.40\n",
       "33     0.80\n",
       "7      0.80\n",
       "1      4.00\n",
       "27     4.00\n",
       "10     4.20\n",
       "36     4.20\n",
       "20     4.40\n",
       "46     4.40\n",
       "30     5.20\n",
       "4      5.20\n",
       "43     5.20\n",
       "17     5.20\n",
       "39     5.40\n",
       "13     5.40\n",
       "45     6.80\n",
       "19     6.80\n",
       "24     7.70\n",
       "50     7.70\n",
       "3      7.80\n",
       "29     7.80\n",
       "31     8.01\n",
       "25     8.01\n",
       "51     8.01\n",
       "5      8.01\n",
       "21     8.46\n",
       "47     8.46\n",
       "32     8.46\n",
       "6      8.46\n",
       "34     8.46\n",
       "8      8.46\n",
       "18     8.90\n",
       "44     8.90\n",
       "22    10.62\n",
       "48    10.62\n",
       "38    11.00\n",
       "12    11.00\n",
       "9     11.48\n",
       "35    11.48\n",
       "42    11.60\n",
       "16    11.60\n",
       "37    12.00\n",
       "11    12.00\n",
       "2     12.32\n",
       "28    12.32\n",
       "26    12.63\n",
       "0     12.63\n",
       "23    16.39\n",
       "49    16.39\n",
       "40    18.56\n",
       "14    18.56\n",
       "Name: Gunning_Fog Score, dtype: float64"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(file['Gunning_Fog Score'].min())\n",
    "print(file['Gunning_Fog Score'].mean())\n",
    "print(file['Gunning_Fog Score'].max())\n",
    "print(file['Gunning_Fog Score'].std())\n",
    "file['Gunning_Fog Score'].sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41    “https://t.co/1lM5Mzu5AX”\n",
      "Name: description, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(file.loc[[41]]['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49    Thanks to Project Runway, Tim Gunn kind of fee...\n",
      "Name: description, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(file.loc[[49]]['description'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
