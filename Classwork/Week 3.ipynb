{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import io\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.util import ngrams\n",
    "from collections import Counter\n",
    "from textblob import TextBlob\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import textstat\n",
    "from statistics import mean\n",
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readFile(url):\n",
    "    download = requests.get(url).content\n",
    "    # Reading the downloaded content and turning it into a pandas dataframe\n",
    "    df = pd.read_csv(io.StringIO(download.decode('utf-8')))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " San Francisco 49ers Wallpaper San Francisco 49ers Wallpaper San Francisco 49ers Glory Years Former San Francisco 49ers Great & Hall of Fame QB; Joe Montana Nick Bosa of the San Francisco 49ers stands on the field during their... nan 49ers players react to Christian McCaffrey's dominant performance vs. Rams San Francisco 49ers 49ers TE George Kittle felt \"great\" after big performance No Huddle Podcast: Milestone episode previews 49ers-Vikings playoff game Olivia Culpo wears black for boyfriend Christian McCafferty 49ers win San Francisco 49ers Frappuccino San Francisco 49ers Joe Montana. Probablemente el mas grande y exitoso mariscal de todas las epocas San Francisco 49ers cheerleader SI's 100 Best Super Bowl Photos San Francisco 49ers Glory Years covers | SI.com Nick Bosa of the San Francisco 49ers reacts after a fumble during the... #LL @lufelive  #football #NFL Joe Montana, San Francisco 49ers Patrick Willis, San Francisco 49ers 2023 San Francisco 49ers wallpaper – Pro Sports Backgrounds San Francisco To-Do List\n"
     ]
    }
   ],
   "source": [
    "# Example 5\n",
    "#I am creating a dictionary here titled inputdata\n",
    "inputdata={}\n",
    "#I am assigning the content of the csv file to my dictionary\n",
    "#header is my row in the csv file that is why header is 0 below\n",
    "inputdata = readFile(\"https://raw.githubusercontent.com/wolfesamk/MSBA-212/main/Files/example2results.csv\").to_dict()\n",
    "\n",
    "#We can use type to check the data type of a variable\n",
    "#print(type(inputdata))\n",
    "\n",
    "#I am using the column headers from the csv file to find the data I am interested to analyze\n",
    "\n",
    "# I created a new dictionary here for the description column in my csv file\n",
    "descriptiondictionary = inputdata.get('description')\n",
    "#print(type(descriptiondictionary))\n",
    "\n",
    "# I am converting the dictionary to a list so I can analyze the data\n",
    "descriptionlist =  list(descriptiondictionary.values())\n",
    "#print(type(descriptionlist))\n",
    "\n",
    "#convert list to string\n",
    "#I need the data in string format for analysis purposes\n",
    "descriptioninstring = ''\n",
    "for eachletter in  descriptionlist:\n",
    "    descriptioninstring += ' '+ str(eachletter)\n",
    "\n",
    "print(descriptioninstring)\n",
    "#print(type(descriptioninstring))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to c:\\Users\\Sam\\AppData\\Loca\n",
      "[nltk_data]     l\\Programs\\Python\\Python311\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(('49ers',), 17), (('san',), 15), (('francisco',), 15)]\n",
      "[(('san', 'francisco'), 15), (('francisco', '49ers'), 14), (('49ers', 'wallpaper'), 3)]\n",
      "[(('san', 'francisco', '49ers'), 14), (('francisco', '49ers', 'wallpaper'), 3), (('49ers', 'wallpaper', 'san'), 2)]\n"
     ]
    }
   ],
   "source": [
    "# Example 6\n",
    "#Access to the string from the previous file and make the string lower case\n",
    "lowercasedescriptions=descriptioninstring.lower()\n",
    "#print(lowercasedescriptions)\n",
    "\n",
    "#remove the url from text to prevent a future error\n",
    "lowercasedescriptions= re.sub(r'\\w+:\\/{2}[\\d\\w-]+(\\.[\\d\\w-]+)*(?:(?:\\/[^\\s/]*))*', '', lowercasedescriptions)\n",
    "#print(lowercasedescriptions)\n",
    "\n",
    "#remove the stop or common words from the string\n",
    "nltk.download('stopwords')\n",
    "#print(stopwords.words('english'))\n",
    "\n",
    "description_tokens = word_tokenize(lowercasedescriptions)\n",
    "\n",
    "description_tokens_without_stopwords = [word for word in description_tokens if not word in stopwords.words()]\n",
    "\n",
    "#print(description_tokens_without_stopwords )\n",
    "\n",
    "unigrams = ngrams(description_tokens_without_stopwords, 1)\n",
    "bigrams = ngrams(description_tokens_without_stopwords,2)\n",
    "trigrams = ngrams(description_tokens_without_stopwords,3)\n",
    "\n",
    "#print (Counter(unigrams))\n",
    "#print (Counter(bigrams))\n",
    "#print (Counter(trigrams))\n",
    "\n",
    "mostcommonunigrams = Counter(unigrams)\n",
    "#This will print top 3 unigrams\n",
    "print(mostcommonunigrams.most_common(3))\n",
    "\n",
    "mostcommonbigrams = Counter(bigrams)\n",
    "print(mostcommonbigrams.most_common(3))\n",
    "\n",
    "mostcommontrigrams = Counter(trigrams)\n",
    "print(mostcommontrigrams.most_common(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to c:\\Users\\Sam\\AppData\\Loca\n",
      "[nltk_data]     l\\Programs\\Python\\Python311\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Common Description Unigrams: [(('witcher',), 6), (('created',), 3), ((':',), 2)]\n",
      "Most Common Title Unigrams: [(('a.r.c.h.i.v.e',), 2), (('.',), 2), (('witcher',), 2)]\n",
      "Most Common Description Bigrams: [(('witcher', '3'), 2), (('-', 'created'), 2), (('pixalry', ':'), 1)]\n",
      "Most Common Title Biigrams: [(('a.r.c.h.i.v.e', '.'), 2), (('.', 'a.r.c.h.i.v.e'), 1), (('.', '7'), 1)]\n",
      "Most Common Description Trigrams: [(('pixalry', ':', '“'), 1), ((':', '“', 'witcher'), 1), (('“', 'witcher', '3'), 1)]\n",
      "Most Common Title Trigrams: [(('a.r.c.h.i.v.e', '.', 'a.r.c.h.i.v.e'), 1), (('.', 'a.r.c.h.i.v.e', '.'), 1), (('a.r.c.h.i.v.e', '.', '7'), 1)]\n"
     ]
    }
   ],
   "source": [
    "# Example 7\n",
    "#I am creating a dictionary here titled inputdata\n",
    "inputdata={}\n",
    "#I am assigning the content of the csv file to my dictionary\n",
    "#header is my row in the csv file that is why header is 0 below\n",
    "inputdata = readFile(\"https://raw.githubusercontent.com/wolfesamk/MSBA-212/main/Files/example4results.csv\").to_dict()\n",
    "\n",
    "#We can use type to check the data type of a variable\n",
    "#print(type(inputdata))\n",
    "\n",
    "#I am using the column headers from the csv file to find the data I am interested to analyze\n",
    "\n",
    "# I created a new dictionary here for the description column in my csv file\n",
    "titledictionary = inputdata.get('title')\n",
    "descriptiondictionary = inputdata.get('description')\n",
    "\n",
    "\n",
    "# I am converting the dictionary to a list so I can analyze the data\n",
    "titlelist = list(titledictionary.values())\n",
    "descriptionlist =  list(descriptiondictionary.values())\n",
    "\n",
    "\n",
    "#convert list to string\n",
    "#I need the data in string format for analysis purposes\n",
    "titleinstring = ''\n",
    "for eachtitleletter in  titlelist:\n",
    "    titleinstring += ' '+ eachtitleletter\n",
    "\n",
    "descriptioninstring = ''\n",
    "for eachdescriptionletter in  descriptionlist:\n",
    "    descriptioninstring += ' '+ eachdescriptionletter\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.util import ngrams\n",
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "\n",
    "#Access to the string from the previous file and make the string lower case\n",
    "lowercasedescriptions=descriptioninstring.lower()\n",
    "lowercasetitles=titleinstring.lower()\n",
    "\n",
    "#remove the url from text to prevent a future error\n",
    "lowercasedescriptions= re.sub(r'\\w+:\\/{2}[\\d\\w-]+(\\.[\\d\\w-]+)*(?:(?:\\/[^\\s/]*))*', '', lowercasedescriptions)\n",
    "lowercasetitles= re.sub(r'\\w+:\\/{2}[\\d\\w-]+(\\.[\\d\\w-]+)*(?:(?:\\/[^\\s/]*))*', '', lowercasetitles)\n",
    "#print(lowercasedescriptions)\n",
    "\n",
    "#remove the stop or common words from the string\n",
    "nltk.download('stopwords')\n",
    "#print(stopwords.words('english'))\n",
    "\n",
    "description_tokens = word_tokenize(lowercasedescriptions)\n",
    "title_tokens = word_tokenize(lowercasetitles)\n",
    "\n",
    "description_tokens_without_stopwords = [word for word in description_tokens if not word in stopwords.words()]\n",
    "\n",
    "title_tokens_without_stopwords = [word for word in title_tokens if not word in stopwords.words()]\n",
    "\n",
    "#print(description_tokens_without_stopwords )\n",
    "\n",
    "descriptionunigrams = ngrams(description_tokens_without_stopwords, 1)\n",
    "descriptionbigrams = ngrams(description_tokens_without_stopwords,2)\n",
    "descriptiontrigrams = ngrams(description_tokens_without_stopwords,3)\n",
    "\n",
    "titleunigrams = ngrams(title_tokens_without_stopwords, 1)\n",
    "titlebigrams = ngrams(title_tokens_without_stopwords,2)\n",
    "titletrigrams = ngrams(title_tokens_without_stopwords,3)\n",
    "\n",
    "#print (Counter(unigrams))\n",
    "#print (Counter(bigrams))\n",
    "#print (Counter(trigrams))\n",
    "\n",
    "mostcommondescriptionunigrams = Counter(descriptionunigrams)\n",
    "mostcommontitleunigrams = Counter(titleunigrams)\n",
    "#This will print top 3 unigrams\n",
    "print(\"Most Common Description Unigrams:\", mostcommondescriptionunigrams.most_common(3))\n",
    "print(\"Most Common Title Unigrams:\",mostcommontitleunigrams.most_common(3))\n",
    "\n",
    "mostcommondescriptionbigrams = Counter(descriptionbigrams)\n",
    "mostcommontitlebigrams = Counter(titlebigrams)\n",
    "print(\"Most Common Description Bigrams:\",mostcommondescriptionbigrams.most_common(3))\n",
    "print(\"Most Common Title Biigrams:\",mostcommontitlebigrams.most_common(3))\n",
    "\n",
    "mostcommondescriptiontrigrams = Counter(descriptiontrigrams)\n",
    "mostcommontitletrigrams = Counter(titletrigrams)\n",
    "print(\"Most Common Description Trigrams:\",mostcommondescriptiontrigrams.most_common(3))\n",
    "print(\"Most Common Title Trigrams:\",mostcommontitletrigrams.most_common(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "# Example 8\n",
    "#I am creating a dictionary here titled inputdata\n",
    "inputdata={}\n",
    "#I am assigning the content of the csv file to my dictionary\n",
    "#header is my row in the csv file that is why header is 0 below\n",
    "inputdata = readFile(\"https://raw.githubusercontent.com/wolfesamk/MSBA-212/main/Files/example4results.csv\").to_dict()\n",
    "\n",
    "#We can use type to check the data type of a variable\n",
    "#print(type(inputdata))\n",
    "\n",
    "#I am using the column headers from the csv file to find the data I am interested to analyze\n",
    "\n",
    "# I created a new dictionary here for the description column in my csv file\n",
    "descriptiondictionary = inputdata.get('description')\n",
    "#I am converting the decription from dictionary to a list for the sentiment analyses below\n",
    "descriptionlist =  list(descriptiondictionary.values())\n",
    "\n",
    "textblob_results_list=[]\n",
    "vader_results_list=[]\n",
    "\n",
    "for i in range(len(descriptionlist )):\n",
    "    #This is TextBlob Based Sentiment Analysis\n",
    "    textblob_analyze_polarity = TextBlob(descriptionlist [i]).polarity\n",
    "    textblob_analyze_subjectivity = TextBlob(descriptionlist [i]).subjectivity\n",
    "    #polarity values range from -1 to 1 where -1.0 is negative polarity and 1.0 is positive\n",
    "    #Subjectivity/objectivity  values range from 0.0 to 1.0 where 0.0 is very objective and 1.0 is very subjective\n",
    "    #print(\"Polarity: \", textblob_analyze_polarity)\n",
    "    #print(\"Subjectivity: \",textblob_analyze_subjectivity)\n",
    "\n",
    "    textblob_result = {\"TextBlob Polarity Score\":textblob_analyze_polarity,\"TextBlob Subjectivity Score\": textblob_analyze_subjectivity}\n",
    "    textblob_results_list.append(textblob_result)\n",
    "\n",
    "    #This is Vader Based Sentiment Analysis\n",
    "    #Vader provides 4 results labeled as negative, neutral, positive, and compound(overall)\n",
    "    vader_sentiment_analysis = SentimentIntensityAnalyzer().polarity_scores(descriptionlist [i])\n",
    "    vader_results_list.append(vader_sentiment_analysis)\n",
    "    #In Vader the compound score is the sum of positive, negative, and neutral scores which is then\n",
    "    #normalized between -1 [most extreme negative] and 1[most extreme positive]\n",
    "    #negative represents negative aspects of a tweet\n",
    "    #positive represents positive aspects of a tweet\n",
    "    #neutral represents neutral aspects of a tweet\n",
    "    #print(\"Polarity Scores in Vader: \", vader_sentiment_analysis)\n",
    "\n",
    "#This is the TextBlob Sentiment Analysis Results\n",
    "textblobresults = pd.DataFrame(textblob_results_list)\n",
    "\n",
    "#This is the Vader Sentiment Analysis Results\n",
    "vaderresults = pd.DataFrame(vader_results_list)\n",
    "#print(textblobresults['TextBlob Polarity Score'])\n",
    "#print(vaderresults['neg'])\n",
    "\n",
    "file = readFile(\"https://raw.githubusercontent.com/wolfesamk/MSBA-212/main/Files/example4results.csv\")\n",
    "file['TextBlob Polarity Score'] = textblobresults['TextBlob Polarity Score']\n",
    "file['TextBlob Subjectivity Score'] = textblobresults['TextBlob Subjectivity Score']\n",
    "file['Vader Negative Polarity Score'] = vaderresults['neg']\n",
    "file['Vader Neutral Polarity Score'] = vaderresults['neu']\n",
    "file['Vader Positive Polarity Score'] = vaderresults['pos']\n",
    "file['Vader Compound Polarity Score'] = vaderresults['compound']\n",
    "\n",
    "#Index is false because example 1.csv file already has an index column\n",
    "file.to_csv('example8results.csv', index=True, index_label=\"Index\")\n",
    "\n",
    "print(\"done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "# Example 9\n",
    "#I am creating a dictionary here titled inputdata\n",
    "inputdata={}\n",
    "#I am assigning the content of the csv file to my dictionary\n",
    "#header is my row in the csv file that is why header is 0 below\n",
    "inputdata = pd.read_csv('example8results.csv', header=[0]).to_dict()\n",
    "\n",
    "#We can use type to check the data type of a variable\n",
    "#print(type(inputdata))\n",
    "\n",
    "#I am using the column headers from the csv file to find the data I am interested to analyze\n",
    "\n",
    "# I created a new dictionary here for the description column in my csv file\n",
    "descriptiondictionary = inputdata.get('description')\n",
    "#I am converting the decription from dictionary to a list for the sentiment analyses below\n",
    "descriptionlist =  list(descriptiondictionary.values())\n",
    "\n",
    "flesch_reading_ease_results_list=[]\n",
    "gunning_fog_results_list=[]\n",
    "\n",
    "for i in range(len(descriptionlist )):\n",
    "    flesch_reading_ease_score=textstat.flesch_reading_ease(descriptionlist[i])\n",
    "    gunning_fog_score=textstat.gunning_fog(descriptionlist[i])\n",
    "    flesch_reading_ease_results_list.append(flesch_reading_ease_score)\n",
    "    gunning_fog_results_list.append(gunning_fog_score)\n",
    "\n",
    "flesch_reading_ease_results = pd.DataFrame(flesch_reading_ease_results_list)\n",
    "gunning_fog_results = pd.DataFrame(gunning_fog_results_list)\n",
    "\n",
    "file = pd.read_csv('example8results.csv')\n",
    "file['Flesch Reading Ease Score'] = flesch_reading_ease_results\n",
    "file['Gunning_Fog Score'] = gunning_fog_results\n",
    "\n",
    "#Index is false because example 8 results.csv file already has an index column\n",
    "file.to_csv('example9results.csv', index=False)\n",
    "print(\"done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Textblob Polarity Score: -0.1412987012987013\n",
      "Average Textblob Subjectivity Score: 0.31805194805194803\n",
      "Average Vader Score: 0.1525\n",
      "\n",
      "\n",
      "Minimum Textblob Polarity Score: -0.75\n",
      "Maximum Textblob Polarity Score: 0.1363636363636363\n",
      "Relationship Between Textblob Polarity Score and Average Vader Compound Score PearsonRResult(statistic=0.762203765961861, pvalue=0.13412484398419286)\n"
     ]
    }
   ],
   "source": [
    "# Example 10\n",
    "#I am creating a dictionary here titled inputdata\n",
    "inputdata={}\n",
    "#I am assigning the content of the csv file to my dictionary\n",
    "#header is my row in the csv file that is why header is 0 below\n",
    "inputdata = pd.read_csv('example8results.csv', header=[0]).to_dict()\n",
    "\n",
    "# I created new dictionaries here\n",
    "textblobpolaritydictionary = inputdata.get('TextBlob Polarity Score')\n",
    "textblobsubjectivitydictionary = inputdata.get('TextBlob Subjectivity Score')\n",
    "vaderdictionary = inputdata.get('Vader Compound Polarity Score')\n",
    "\n",
    "#Convert the dictionaries into lists\n",
    "textblobpolaritylist= list(textblobpolaritydictionary.values())\n",
    "textblobsubjectivitylist= list(textblobsubjectivitydictionary.values())\n",
    "vaderlist= list(vaderdictionary.values())\n",
    "\n",
    "averagetextblobpolarityscore=mean(textblobpolaritylist)\n",
    "averagetextblobsubjectivityscore=mean(textblobsubjectivitylist)\n",
    "averagevaderscore=mean(vaderlist)\n",
    "\n",
    "print(\"Average Textblob Polarity Score:\", averagetextblobpolarityscore)\n",
    "print(\"Average Textblob Subjectivity Score:\", averagetextblobsubjectivityscore)\n",
    "print(\"Average Vader Score:\", averagevaderscore)\n",
    "\n",
    "minimumtextblobpolarityscore=min(textblobpolaritylist)\n",
    "maximumtextblobpolarityscore=max(textblobpolaritylist)\n",
    "\n",
    "#\\n means go to the line below in order to read printed results easier.\n",
    "print(\"\\n\")\n",
    "print(\"Minimum Textblob Polarity Score:\", minimumtextblobpolarityscore)\n",
    "print(\"Maximum Textblob Polarity Score:\", maximumtextblobpolarityscore)\n",
    "\n",
    "relationshipbetweentextblobpolarityscoreandvadercompoundscore= pearsonr(textblobpolaritylist,vaderlist)\n",
    "\n",
    "print(\"Relationship Between Textblob Polarity Score and Average Vader Compound Score\", relationshipbetweentextblobpolarityscoreandvadercompoundscore)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
